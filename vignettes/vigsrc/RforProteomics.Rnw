%\VignetteEngine{knitr}
%\VignetteIndexEntry{Using R for proteomics data analysis}
%\VignetteKeywords{Bioinformatics, proteomics, mass spectrometry, tutorial, data}
%\VignettePackage{RforProteomics}

\documentclass{article}

\usepackage{longtable}

<<biocstyle, eval=TRUE, echo=FALSE, results="asis">>=
BiocStyle::latex()
@

\author{
  Laurent Gatto\footnote{\email{lg390@cam.ac.uk}, \url{http://cpu.sysbiol.cam.ac.uk}}~,
  Thomas Lin Pedersen,
  Sebastian Gibb}

\title{Using \R{} and \Bioconductor{} for Proteomics Data Analysis}

\begin{document}

\maketitle

<<env0, echo = FALSE, warning = FALSE, message=FALSE>>=
suppressPackageStartupMessages(library("BiocInstaller"))
## suppressPackageStartupMessages(library("parallel"))
suppressPackageStartupMessages(library("MSnbase"))
suppressPackageStartupMessages(library("mzID"))
suppressPackageStartupMessages(library("rpx"))
suppressPackageStartupMessages(library("isobar"))
suppressPackageStartupMessages(library("MALDIquant"))
suppressPackageStartupMessages(library("MALDIquantForeign"))
suppressPackageStartupMessages(library("IPPD"))
suppressPackageStartupMessages(library("rols"))
suppressPackageStartupMessages(library("hpar"))
suppressPackageStartupMessages(library("BRAIN"))
suppressPackageStartupMessages(library("org.Hs.eg.db"))
suppressPackageStartupMessages(library("GO.db"))
suppressPackageStartupMessages(library("Rdisop"))
suppressPackageStartupMessages(library("rTANDEM"))
suppressPackageStartupMessages(library("MSGFplus"))
suppressPackageStartupMessages(library("MSGFgui"))
@

<<'setup', include = FALSE, cache = FALSE>>=
library("knitr")
opts_chunk$set(tidy.opts =
                   list(width.cutoff = 50,
                   tidy = FALSE),
               fig.align = 'center',
               stop_on_error = 1L)
options(width = 60)
@
%% $

%% Abstract and keywords %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vskip 0.3in minus 0.1in
\hrule
\begin{abstract}
  This vignette shows and executes the code presented in the
  manuscript \textit{Using \R{} for proteomics data analysis}.  It also
  aims at being a general overview for users who wish to explore the
  \R{} environment and programming language for the analysis of
  proteomics data.
\end{abstract}

\textit{Keywords}: proteomics, mass spectrometry, tutorial.
\vskip 0.1in minus 0.05in
\hrule
\vskip 0.2in minus 0.1in
\vspace{10mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\tableofcontents

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Section
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{sec:intro}

This document illustrates some existing \R{} infrastructure for the
analysis of proteomics data.  It presents the code for the use cases
taken from \cite{R4prot2013}. A pre-print of the manuscript is
available on arXiv\footnote{\url{http://arxiv.org/abs/1305.6559}}.

There are however numerous additional \R{} resources distributed by the
\Bioconductor{}\footnote{\url{http://www.bioconductor.org}} and
CRAN\footnote{\url{http://cran.r-project.org/web/packages/}}
repositories, as well as packages hosted on personal websites. Section
\ref{sec:packages} on page \pageref{sec:packages} tries to provide a
wider picture of available packages, without going into details.

\subsection{General \R{} resources}

The reader is expected to have basic \R{} knowledge to find the document
helpful. There are numerous \R{} introductions freely available, some of
which are listed below.

From the \R{} project web-page:
\begin{itemize}
\item \textbf{An Introduction to R} is based on the former \textit{Notes on R},
  gives an introduction to the language and how to use R for doing statistical
  analysis and graphics.
  [\href{http://cran.r-project.org/doc/manuals/R-intro.html}{browse HTML} |
    \href{http://cran.r-project.org/doc/manuals/R-intro.pdf}{download PDF}]
  \item Several introductory tutorials in the
    \href{http://cran.r-project.org/other-docs.html}{contributed
      documentation} section.
  \item The \texttt{TeachingMaterial}
    repository\footnote{\href{https://github.com/lgatto/TeachingMaterial}{https://github.com/lgatto/TeachingMaterial}}
    contains several sets of slides and vignettes about \R{}
    programming.
\end{itemize}

Relevant background on the \R{} software and its application to
computational biology in general and proteomics in particular can also
be found in \cite{R4prot2013}. For details about the \Bioconductor{}
project, the reader is referred to \cite{Gentleman2004}.

\subsection{Getting help}

All \R{} packages come with ample documentation. Every command
(function, class or method) a user is susceptible to use is
documented. The documentation can be accessed by preceding the command
by a \texttt{?} in the \R{} console. For example, to obtain help about
the \Rfunction{library} function, that will be used in the next
section, one would type \Rfunction{?library}. In addition, all
\Bioconductor{} packages come with at least one vignette (this document
is the vignette that comes with the \Biocpkg{RforProteomics}
package), a document that combines text and \R{} code that is executed
before the pdf is assembled. To look up all vignettes that come with a
package, say \Biocpkg{RforProteomics} and then open the vignette of
interest, one uses the \Rfunction{vignette} function as illustrated
below. More details can be found in \Rfunction{?vignette}.

<<vignette1, echo = TRUE, eval = FALSE>>=
## list all the vignettes in the RforProteomics package
vignette(package = "RforProteomics")
## Open the vignette called RforProteomics
vignette("RforProteomics", package = "RforProteomics")
## or just
vignette("RforProteomics")
@


\R{} has several mailing
lists\footnote{\url{http://www.r-project.org/mail.html}}. The most
relevant here being the main \texttt{R-help} list, \textit{for
  discussion about problem and solutions using \R{}}. This one is for
general \R{} content and is not suitable for bioinformatics or
proteomics questions. \Bioconductor{} also offers several mailing
lists\footnote{\url{http://bioconductor.org/help/mailing-list/}}
dedicated to bioinformatics matters and \Bioconductor{} packages. The
main \Bioconductor{} list is the most relevant one. It is possible to
post\footnote{\url{http://bioconductor.org/help/mailing-list/mailform/}}
questions without subscribing to the list. Finally, the dedicated
\Biocpkg{RforProteomics} Google
group\footnote{\url{https://groups.google.com/forum/\#!forum/rbioc-sig-proteomics}}
welcomes questions/comments/annoucements related to \R{} and
mass-spectrometry/proteomics.

It is important to read and comply to the posting guides
(\href{http://www.r-project.org/posting-guide.html}{here} and
\href{http://bioconductor.org/help/mailing-list/posting-guide/}{here})
to maximise the chances to obtain good responses. It is important to
specify the software versions using the \Rfunction{sessionInfo()}
functions (see an example output at the end of this document, on page
\pageref{sec:sessionInfo}). It the question involves some code, make
sure to isolate the relevant portion and report it with your question,
trying to make your code/example
reproducible\footnote{\url{https://github.com/hadley/devtools/wiki/Reproducibility}}.

All lists have browsable archives.

\subsection{Installation}

The package should be installed using as described below:

<<installation, eval = FALSE>>=
## only first time you install Bioconductor packages
source("http://www.bioconductor.org/biocLite.R")
## else
library("BiocInstaller")
biocLite("RforProteomics")
@

To install all dependencies and reproduce the code in the vignette,
replace the last line in the code chunk above with:)

<<installation2, eval = FALSE>>=
biocLite("RforProteomics", dependencies = TRUE)
@

Finally, the package can be loaded with

<<loadR4Prot>>=
library("RforProteomics")
@

See also the \Biocpkg{RforProteomics} web
page\footnote{\url{http://lgatto.github.io/RforProteomics/}} for more
information on installation.

\subsection{External dependencies}

Some packages used in the document depend on external libraries that
need to be installed prior to the \R{} packages:

\begin{description}
\item[\Biocpkg{mzR}] depends on the Common Data
  Format\footnote{\url{http://cdf.gsfc.nasa.gov/}} (CDF) to CDF-based
  raw mass-spectrometry data. On Linux, the \texttt{libcdf} library is
  required.  On Debian-based systems, for instance, one needs to
  install the \texttt{libnetcdf-dev} package.
\item[\Biocpkg{IPPD}] (and others) depend on the \CRANpkg{XML}
  package which requires the \texttt{libxml2} infrastructure on
  Linux. On Debian-based systems, one needs to install
  \texttt{libxml2-dev}.
\item [\Biocpkg{biomaRt}] performs on-line requests using the
  \texttt{curl}\footnote{\url{http://curl.haxx.se/}}
  infrastructure. On Debian-based systems, you one needs to install
  \texttt{libcurl-dev} or \texttt{libcurl4-openssl-dev}.
  \item[\Biocpkg{MSGFplus}] Is based on the MS-GF+ java program and thus
  requires Java 1.7\footnote{\url{https://java.com}} in order to work.
\end{description}

\subsection{Obtaining the code}

The code in this document describes all the examples presented in
\cite{R4prot2013} and can be copy, pasted and executed. It is however
more convenient to have it in a separate text file for better
interaction with \R{} (using
ESS\footnote{\url{http://ess.r-project.org/}} for Emacs or
RStudio\footnote{\url{http://rstudio.org/}} for instance) to easily
modify and explore it. This can be achieved with the
\Rfunction{Stangle} function. One needs the Sweave source of this
document (a document combining the narration and the \R{} code) and the
\Rfunction{Stangle} then specifically extracts the code chunks and
produces a clean \R{} source file. If the package is installed, the
following code chunk will create a \texttt{RforProteomics.R} file in
your working directory containing all the annotated source code
contained in this document.

<<stangle, eval=TRUE, tidy=FALSE, error=FALSE>>=
## gets the vignette source
rnwfile <- system.file("doc/vigsrc/RforProteomics.Rnw",
                       package = "RforProteomics")
## produces the R file in the working directory
library("knitr")
purl(rnwfile, quiet = TRUE)
@ %% $

Alternatively, you can obtain the \texttt{Rnw} file on the github page
\url{https://github.com/lgatto/RforProteomics/blob/master/inst/doc/vigsrc/RforProteomics.Rnw}.

\subsection{Prepare the working environment}

The packages that we will depend on to execute the examples will be
loaded in the respective sections. Here, we pre-load packages that
provide general functionality used throughout the document.

<<env>>=
library("RColorBrewer") ## Color palettes
library("ggplot2")  ## Convenient and nice plotting
library("reshape2") ## Flexibly reshape data
@

\section{Data standards and input/output}

\subsection{The \Biocpkg{mzR} package}\ref{sec:mzr}

\subsubsection{Raw MS data}

The \Biocpkg{mzR} package \cite{Chambers2012} provides a unified
interface to various mass spectrometry open formats.  This code chunk,
taken from the \Rfunction{openMSfile} documentation, illustrated how
to open a connection to an raw data file. The example \texttt{mzML}
data is taken from the \Biocexptpkg{msdata} data package.  The code
below would also be applicable to an \texttt{mzXML}, \texttt{mzData}
or \texttt{netCDF} file.

<<mzr>>=
## load the required packages
library("mzR") ## the software package
library("msdata") ## the data package
## below, we extract the releavant example file
## from the local 'msdata' installation
filepath <- system.file("microtofq", package = "msdata")
file <- list.files(filepath, pattern="MM14.mzML",
                   full.names=TRUE, recursive = TRUE)
## creates a commection to the mzML file
mz <- openMSfile(file)
## demonstraction of data access
basename(fileName(mz))
isInitialized(mz)
runInfo(mz)
instrumentInfo(mz)
## once finished, it is good to explicitely
## close the connection
close(mz)
@

\Biocpkg{mzR} is used by other packages, like \Biocpkg{MSnbase}
\cite{Gatto2012}, \Biocpkg{TargetSearch} \cite{TargetSearch2009} and
\Biocpkg{xcms} \cite{Smith2006, Benton2008, Tautenhahn2008}, that
provide a higher level abstraction to the data.

\subsubsection{Identification data}

The \Biocpkg{mzR} package also provides very fast access to
\texttt{mzIdentML} data by leveraging proteowizard's \texttt{C++}
parser.

<<mzrid>>=
file <- system.file("mzid", "Tandem.mzid.gz", package="msdata")
mzid <- openIDfile(file)
mzid
@

Once and \Robject{mzRident} identification file handle has been
established, various data and metadata can be extracted, as
illustrated below.

<<mzrid2>>=
softwareInfo(mzid)
enzymes(mzid)
names(psms(mzid))
head(psms(mzid))[, 1:13]
@

\subsection{Handling MS$^2$ identification data with \Biocpkg{mzID}}
\label{subsec:mzID}

The \Biocpkg{mzID} package allows to load and manipulate MS$^2$ data
in the \texttt{mzIdentML} format. The main \Rfunction{mzID} function
reads such a file and constructs an instance of class \Robject{mzID}.

<<mzid1>>=
library("mzID")
id <- mzID("http://psi-pi.googlecode.com/svn/trunk/examples/1_1examples/55merge_tandem.mzid")
id
@

Multiple files can be parsed in one go, possibly in parallel if the
environment supports it. When this is done an mzIDCollection object
is returned:

<<mzid2>>=
ids <- mzID(c(
    "http://psi-pi.googlecode.com/svn/trunk/examples/1_1examples/55merge_tandem.mzid",
    "http://psi-pi.googlecode.com/svn/trunk/examples/1_1examples/55merge_omssa.mzid"))
ids
@

Peptides, scans, parameters, \ldots can be extracted with the
respective \Rfunction{pepetides}, \Rfunction{scans},
\Rfunction{parameters}, \ldots functions. The \Robject{mzID} object
can also be converted into a \texttt{data.frame} using the
\Rfunction{flatten} function.

<<flatid>>=
fid <- flatten(id)
names(fid)
dim(fid)
@


\section{Raw data abstraction with \Robject{MSnExp} objects}

\Biocpkg{MSnbase} \cite{Gatto2012} provides base functions and
classes for MS-based proteomics that allow facile data and meta-data
processing, manipulation and plotting (see for instance figure
\ref{fig:msnexp} on page \pageref{fig:msnexp}).

<<msnexp>>=
library("MSnbase")
## uses a simple dummy test included in the package
mzXML <- dir(system.file(package="MSnbase",dir="extdata"),
             full.name=TRUE,
             pattern="mzXML$")
basename(mzXML)
## reads the raw data into and MSnExp instance
raw <- readMSData(mzXML, verbose = FALSE)
raw
## Extract a single spectrum
raw[[3]]
@
%% $

\begin{figure}[!ht]
<<msnexpPlot, dev='pdf', echo=TRUE, fig.width=5, fig.height=5, fig.keep='all', out.width='.48\\linewidth'>>=
plot(raw, full=TRUE)
plot(raw[[3]], full=TRUE, reporters=iTRAQ4)
@
\caption{The \Rfunction{plot} method can be used on experiments,
  i.e. spectrum collections (top), or individual spectra (bottom). }
\label{fig:msnexp}
\end{figure}

\clearpage

\subsection{\texttt{mgf} read/write support}

Read and write support for data in the
\texttt{mgf}\footnote{\url{http://www.matrixscience.com/help/data_file_help.html\#GEN}}
and \texttt{mzTab}\footnote{\url{https://code.google.com/p/mztab/}}
formats are available via the
\Rfunction{readMgfData}/\Rfunction{writeMgfData} and
\Rfunction{readMzTabData}/\Rfunction{writeMzTabData} functions,
respectively. An example for the latter is shown in the next section.

\section{Quantitative proteomics}

As an running example throughout this document, we will use a TMT
6-plex data set, \texttt{PXD000001} to illustrate quantitative data
processing.  The code chunk below first downloads this data file from
the ProteomeXchange server using the \Biocpkg{rpx} package.

\subsection{The \texttt{mzTab} format}

The first code chunk downloads the \texttt{mzTab} data from the
ProteomeXchange repository \cite{Vizcaino2014}.

<<downloadmztab, tidy = FALSE>>=
## Experiment information
library("rpx")
px1 <- PXDataset("PXD000001")
px1
pxfiles(px1)
## Downloading the mzTab data
mztab <- pxget(px1, "PXD000001_mztab.txt")
mztab
@

The code below loads the \texttt{mzTab} file into \R{} and generates an
\Robject{MSnSet} instance, removes missing values and calculates
protein intensities by summing the peptide quantitation data. Figure
\ref{fig:matplot} illustrates the intensities for 5 proteins.


<<mztab, tidy = FALSE>>=
## Load mzTab peptide data
qnt <- readMzTabData(mztab, what = "PEP")
sampleNames(qnt) <- reporterNames(TMT6)
head(exprs(qnt))
## remove missing values
qnt <- filterNA(qnt)
processingData(qnt)

## combine into proteins
## - using the 'accession' feature meta data
## - sum the peptide intensities
protqnt <- combineFeatures(qnt,
                           groupBy = fData(qnt)$accession,
                           fun = sum)
@



\begin{figure}[!ht]
<<matplot, dev='pdf', echo=TRUE, fig.width=5.5, fig.height=5.5, fig.keep='last', out.width='.6\\linewidth', tidy=FALSE>>=
cls <- brewer.pal(5, "Set1")
matplot(t(tail(exprs(protqnt), n = 5)), type = "b",
        lty = 1, col = cls,
        ylab = "Protein intensity (summed peptides)",
        xlab = "TMT reporters")
legend("topright", tail(featureNames(protqnt), n=5),
       lty = 1, bty = "n", cex = .8, col = cls)
@
\caption{Protein quantitation data. }
\label{fig:matplot}
\end{figure}

<<mztab2>>=
qntS <- normalise(qnt, "sum")
qntV <- normalise(qntS, "vsn")
qntV2 <- normalise(qnt, "vsn")

acc <- c("P00489", "P00924",
         "P02769", "P62894",
         "ECA")

idx <- sapply(acc, grep, fData(qnt)$accession)
idx2 <- sapply(idx, head, 3)
small <- qntS[unlist(idx2), ]

idx3 <- sapply(idx, head, 10)
medium <- qntV[unlist(idx3), ]

m <- exprs(medium)
colnames(m) <- c("126", "127", "128",
                 "129", "130", "131")
rownames(m) <- fData(medium)$accession
rownames(m)[grep("CYC", rownames(m))] <- "CYT"
rownames(m)[grep("ENO", rownames(m))] <- "ENO"
rownames(m)[grep("ALB", rownames(m))] <- "BSA"
rownames(m)[grep("PYGM", rownames(m))] <- "PHO"
rownames(m)[grep("ECA", rownames(m))] <- "Background"

cls <- c(brewer.pal(length(unique(rownames(m)))-1, "Set1"),
         "grey")
names(cls) <- unique(rownames(m))
wbcol <- colorRampPalette(c("white", "darkblue"))(256)
@ %% $

\begin{figure}[!ht]
<<heatmap, dev='pdf', echo=TRUE, fig.width=5.5, fig.height=5.5, fig.keep='last', out.width='.6\\linewidth'>>=
heatmap(m, col = wbcol, RowSideColors=cls[rownames(m)])
@
\caption{A heatmap. }
\label{fig:heatmap}
\end{figure}


\begin{figure}[!ht]
<<spikes, dev='pdf', echo=TRUE, fig.width=9, fig.height=5, fig.keep='all', out.width='1\\linewidth', tidy=FALSE>>=
dfr <- data.frame(exprs(small),
                  Protein = as.character(fData(small)$accession),
                  Feature = featureNames(small),
                  stringsAsFactors = FALSE)
colnames(dfr) <- c("126", "127", "128", "129", "130", "131",
                   "Protein", "Feature")
dfr$Protein[dfr$Protein == "sp|P00924|ENO1_YEAST"] <- "ENO"
dfr$Protein[dfr$Protein == "sp|P62894|CYC_BOVIN"]  <- "CYT"
dfr$Protein[dfr$Protein == "sp|P02769|ALBU_BOVIN"] <- "BSA"
dfr$Protein[dfr$Protein == "sp|P00489|PYGM_RABIT"] <- "PHO"
dfr$Protein[grep("ECA", dfr$Protein)] <- "Background"
dfr2 <- melt(dfr)
ggplot(aes(x = variable, y = value, colour = Protein),
       data = dfr2) +
  geom_point() +
  geom_line(aes(group=as.factor(Feature)), alpha = 0.5) +
  facet_grid(. ~ Protein) + theme(legend.position="none") +
  labs(x = "Reporters", y = "Normalised intensity")
@ %% $
\caption{Spikes plot using \CRANpkg{ggplot2}.}
\label{fig:spikes}
\end{figure}

\clearpage

\subsection{Working with raw data}

We reuse our dedicated \Robject{px1} ProteomeXchange data object to
download the raw data (in \texttt{mzXML} format) and load it with the
\Rfunction{readMSData} from the \Biocpkg{MSnbase} package that
produces a raw data experiment object of class \Robject{MSnExp}. The
raw data is then quantified using the \Rfunction{quantify} method
specifying the TMT 6-plex isobaric tags and a 7$^{th}$ peak of
interest corresponding to the un-dissociated reporter tag peaks (see
the \texttt{MSnbase-demo} vignette in \Biocpkg{MSnbase} for details).

<<mzxmlqnt, cache=TRUE>>=
mzxml <- pxget(px1, "TMT_Erwinia_1uLSike_Top10HCD_isol2_45stepped_60min_01.mzXML")
rawms <- readMSData(mzxml, centroided = TRUE, verbose = FALSE)
qntms <- quantify(rawms, reporters = TMT7, method = "max")
qntms
@

Identification data in the \texttt{mzIdentML} format can be added to
\Robject{MSnExp} or \Robject{MSnSet} instances with the
\Rfunction{addIdentificationData} function. See the function
documentation for examples.

<<qntdf>>=
d <- data.frame(Signal = rowSums(exprs(qntms)[, 1:6]),
                Incomplete = exprs(qntms)[, 7])
d <- log(d)
cls <- rep("#00000050", nrow(qnt))
pch <- rep(1, nrow(qnt))
cls[grep("P02769", fData(qnt)$accession)] <- "gold4" ## BSA
cls[grep("P00924", fData(qnt)$accession)] <- "dodgerblue" ## ENO
cls[grep("P62894", fData(qnt)$accession)] <- "springgreen4" ## CYT
cls[grep("P00489", fData(qnt)$accession)] <- "darkorchid2" ## PHO
pch[grep("P02769", fData(qnt)$accession)] <- 19
pch[grep("P00924", fData(qnt)$accession)] <- 19
pch[grep("P62894", fData(qnt)$accession)] <- 19
pch[grep("P00489", fData(qnt)$accession)] <- 19
@

<<mzp, cache = TRUE, fig.keep='none', warning = FALSE>>=
mzp <- plotMzDelta(rawms, reporters = TMT6, verbose = FALSE) + ggtitle("")
@

\begin{figure}[!ht]
<<plotmzdelta, dev='pdf', echo=TRUE, fig.width=8, fig.height=5, fig.keep='last', out.width='0.9\\linewidth', warning = FALSE>>=
mzp
@
\caption{A m/z delta plot.}
\label{fig:plotmzdelta}
\end{figure}


\begin{figure}[!ht]
<<incompl, dev='pdf', echo=TRUE, fig.width=5.5, fig.height=5.5, fig.keep='last', out.width='.6\\linewidth', tidy=FALSE>>=
plot(Signal ~ Incomplete, data = d,
     xlab = expression(Incomplete~dissociation),
     ylab = expression(Sum~of~reporters~intensities),
     pch = 19,
     col = "#4582B380")
grid()
abline(0, 1, lty = "dotted")
abline(lm(Signal ~ Incomplete, data = d), col = "darkblue")
@
\caption{Incomplete dissociation.}
\label{fig:incompl}
\end{figure}


\begin{figure}[!ht]
<<maplot, dev='pdf', echo=TRUE, fig.width=5.5, fig.height=5.5, fig.keep='last', out.width='.6\\linewidth'>>=
MAplot(qnt[, c(4, 2)], cex = .9, col = cls, pch = pch, show.statistics = FALSE)
@
\caption{MAplot on an \Robject{MSnSet} instance.}
\label{fig:maplot}
\end{figure}

\clearpage

\subsection{The \CRANpkg{MALDIquant} package}

This section illustrates some of \CRANpkg{MALDIquant}'s data
processing capabilities \cite{Gibb2012}.  The code is taken from the
\texttt{processing-peaks.R} script downloaded from the package
homepage\footnote{\url{http://strimmerlab.org/software/maldiquant/}}.

\subsubsection*{Loading the data}

<<mqload, tidy=FALSE>>=
## load packages
library("MALDIquant")
library("MALDIquantForeign")
## getting test data
datapath <-
  file.path(system.file("Examples",
                        package = "readBrukerFlexData"),
            "2010_05_19_Gibb_C8_A1")
dir(datapath)
sA1 <- importBrukerFlex(datapath, verbose=FALSE)
# in the following we use only the first spectrum
s <- sA1[[1]]

summary(mass(s))
summary(intensity(s))
head(as.matrix(s))
@

\begin{figure}[!ht]
<<mqplot, dev='pdf', echo=TRUE, fig.width=7, fig.height=5.5, fig.keep='last', out.width='.6\\linewidth'>>=
plot(s)
@
\caption{Spectrum plotting in \CRANpkg{MALDIquant}.}
\label{fig:mqplot}
\end{figure}

\subsubsection*{Preprocessing}

<<mqpreproc>>=
## sqrt transform (for variance stabilization)
s2 <- transformIntensity(s, method="sqrt")
s2

## smoothing - 5 point moving average
s3 <- smoothIntensity(s2, method="MovingAverage", halfWindowSize=2)
s3

## baseline subtraction
s4 <- removeBaseline(s3, method="SNIP")
s4
@

\subsubsection*{Peak picking}

<<mqred>>=
## peak picking
p <- detectPeaks(s4)
length(p) # 181
peak.data <- as.matrix(p) # extract peak information
@


\begin{figure}[!ht]
<<mqplot2, dev='pdf', echo=TRUE, fig.width=10, fig.height=5, fig.keep='high', out.width='1\\linewidth'>>=
par(mfrow=c(2,3))
xl <- range(mass(s))
# use same xlim on all plots for better comparison
plot(s, sub="", main="1: raw", xlim=xl)
plot(s2, sub="", main="2: variance stabilisation", xlim=xl)
plot(s3, sub="", main="3: smoothing", xlim=xl)
plot(s4, sub="", main="4: base line correction", xlim=xl)
plot(s4, sub="", main="5: peak detection", xlim=xl)
points(p)
top20 <- intensity(p) %in% sort(intensity(p), decreasing=TRUE)[1:20]
labelPeaks(p, index=top20, underline=TRUE)
plot(p, sub="", main="6: peak plot", xlim=xl)
labelPeaks(p, index=top20, underline=TRUE)
@
\caption{Spectrum plotting in \CRANpkg{MALDIquant}.}
\label{fig:mqplot}
\end{figure}

\clearpage

\subsection{Working with peptide sequences}

<<isotopes, tidy = FALSE, warning = FALSE>>=
library(IPPD)
library(BRAIN)
atoms <- getAtomsFromSeq("SIVPSGASTGVHEALEMR")
unlist(atoms)

library(Rdisop)
pepmol <- getMolecule(paste0(names(atoms),
                             unlist(atoms),
                             collapse = ""))
pepmol

##
library(OrgMassSpecR)
data(itraqdata)

simplottest <-
  itraqdata[featureNames(itraqdata) %in% paste0("X", 46:47)]
sim <- SpectrumSimilarity(as(simplottest[[1]], "data.frame"),
                          as(simplottest[[2]], "data.frame"),
                          top.lab = "itraqdata[['X46']]",
                          bottom.lab = "itraqdata[['X47']]",
                          b = 25)
title(main = paste("Spectrum similarity", round(sim, 3)))

MonoisotopicMass(formula = list(C = 2, O = 1, H=6))
molecule <- getMolecule("C2H5OH")
molecule$exactmass
## x11()
## plot(t(.pepmol$isotopes[[1]]), type = "h")

## x <- IsotopicDistribution(formula = list(C = 2, O = 1, H=6))
## t(molecule$isotopes[[1]])
## par(mfrow = c(2,1))
## plot(t(molecule$isotopes[[1]]), type = "h")
## plot(x[, c(1,3)], type = "h")

## data(myo500)
## masses <- c(147.053, 148.056)
## intensities <- c(93, 5.8)
## molecules <- decomposeIsotopes(masses, intensities)

## experimental eno peptides
exppep <-
  as.character(fData(qnt[grep("ENO", fData(qnt)[, 2]), ])[, 1]) ## 13
minlength <- min(nchar(exppep))


if (!file.exists("P00924.fasta"))
    eno <- download.file("http://www.uniprot.org/uniprot/P00924.fasta",
                         destfile = "P00924.fasta")
eno <- paste(readLines("P00924.fasta")[-1], collapse = "")
enopep <- Digest(eno, missed = 1)
nrow(enopep) ## 103
sum(nchar(enopep$peptide) >= minlength) ## 68
pepcnt <- enopep[enopep[, 1] %in% exppep, ]
nrow(pepcnt) ## 13
@

The following code chunks demonstrate how to use the \Biocpkg{cleaver} package
for in-silico cleavage of polypeptides, e.g. cleaving of
\emph{Gastric juice peptide 1 (P01358)} using \emph{Trypsin}:
<<cleaver, tidy = FALSE>>=
library(cleaver)
cleave("LAAGKVEDSD", enzym = "trypsin")
@

Sometimes cleavage is not perfect and the enzym miss some cleavage positions:

<<cleaver_missing, tidy = FALSE>>=
## miss one cleavage position
cleave("LAAGKVEDSD", enzym = "trypsin", missedCleavages = 1)

## miss zero or one cleavage positions
cleave("LAAGKVEDSD", enzym = "trypsin", missedCleavages = 0:1)
@


Example code to generate an Texshade image to be included directly in
a Latex document or \R{} vignette is presented below.  The \R{} code
generates a Texshade environment and the annotated sequence display
code that is written to a \TeX~file that can itself be included into a
\LaTeX~of Sweave document.

{\scriptsize
\begin{verbatim}
seq1file <- "seq1.tex"
cat("\\begin{texshade}{Figures/P00924.fasta}
     \\setsize{numbering}{footnotesize}
     \\setsize{residues}{footnotesize}
     \\residuesperline*{70}
     \\shadingmode{functional}
     \\hideconsensus
     \\vsepspace{1mm}
     \\hidenames
     \\noblockskip\n", file = seq1file)
tmp <- sapply(1:nrow(pepcnt), function(i) {
  col <- ifelse((i %% 2) == 0, "Blue", "RoyalBlue")
  cat("\\shaderegion{1}{", pepcnt$start[i], "..", pepcnt$stop[i], "}{White}{", col, "}\n",
      file = seq1file, append = TRUE)
})
cat("\\end{texshade}
    \\caption{Visualising observed peptides for the Yeast enolase protein. Peptides are shaded in blue and black.
              The last peptide is a mis-cleavage and overlaps with \\texttt{IEEELGDNAVFAGENFHHGDK}.}
    \\label{fig:seq}
  \\end{center}
\\end{figure}\n\n",
    file = seq1file, append = TRUE)
\end{verbatim}
}


\subsubsection*{$^{15}N$ incorporation}

\begin{figure}[!ht]
<<n15, dev='pdf', echo=TRUE, fig.width=8, fig.height=7, fig.keep='high', out.width='.9\\linewidth', tidy=FALSE, cache=TRUE>>=
## 15N incorporation rates from 0, 0.1, ..., 0.9, 0.95, 1
incrate <- c(seq(0, 0.9, 0.1), 0.95, 1)
inc <- lapply(incrate, function(inc)
              IsotopicDistributionN("YEVQGEVFTKPQLWP", inc))
par(mfrow = c(4,3))
for (i in 1:length(inc))
  plot(inc[[i]][, c(1, 3)], xlim = c(1823, 1848), type = "h",
       main = paste0("15N incorporation at ", incrate[i]*100, "%"))
@
\caption{Isotopic envelope for the \texttt{YEVQGEVFTKPQLWP} peptide at different $^{15}N$ incorporation rates. }
\label{fig:n15}
\end{figure}

\clearpage

\subsection{The \Biocpkg{isobar} package}

The \Biocpkg{isobar} package \cite{Breitwieser2011} provides methods for the statistical
analysis of isobarically tagged MS$^2$ experiments.

%% <<isobarfix, echo=TRUE>>=
%% ## temporary local fix
%% subsetIBSpectra <-
%%   function (x, protein = NULL,
%%             peptide = NULL, direction = "exclude",
%%             specificity =
%%             c(REPORTERSPECIFIC, GROUPSPECIFIC, UNSPECIFIC),
%%             ...)
%% {
%%     if (is.null(protein))
%%         sel.spectra <- spectrumSel(x, peptide = peptide, ...)
%%     else sel.spectra <- spectrumSel(x,
%%                                     protein = protein,
%%                                     specificity = specificity,
%%         ...)
%%     if (direction == "exclude")
%%         sel.spectra <- !sel.spectra
%%     for (aden in assayDataElementNames(x)) {
%%         assayDataElement(x, aden) <-
%%           assayDataElement(x, aden)[sel.spectra,             ]
%%     }
%%     ## changed this from as.data.frame
%%     pg.df <- as(proteinGroup(x), "data.frame")
%%     proteinGroup(x) <-
%%       ProteinGroup(pg.df[pg.df[, "spectrum"] %in%
%%         fData(x)[sel.spectra, "spectrum"], ])
%%     featureData(x) <- as(fData(x)[sel.spectra, ],
%%                          "AnnotatedDataFrame")
%%     x
%% }
%% @

<<isobar, cache=TRUE, tidy=FALSE>>=
library(isobar)

## Prepare the PXD000001 data for isobar analysis
.ions <- exprs(qnt)
.mass <- matrix(mz(TMT6), nrow(qnt), byrow=TRUE, ncol = 6)
colnames(.ions) <- colnames(.mass) <-
  reporterTagNames(new("TMT6plexSpectra"))
rownames(.ions) <- rownames(.mass) <-
  paste(fData(qnt)$accession, fData(qnt)$sequence, sep = ".")
pgtbl <- data.frame(spectrum = rownames(.ions),
                    peptide = fData(qnt)$sequence,
                    modif = ":",
                    start.pos = 1,
                    protein = fData(qnt)$accession,
                    accession = fData(qnt)$accession)
x <- new("TMT6plexSpectra", pgtbl, .ions, .mass)
featureData(x)$proteins <- as.character(fData(qnt)$accession)

x <- correctIsotopeImpurities(x) ## using identity matrix here
x <- normalize(x, per.file = FALSE)
## spikes
spks <- c(protein.g(proteinGroup(x), "P00489"),
          protein.g(proteinGroup(x), "P00924"),
          protein.g(proteinGroup(x), "P02769"),
          protein.g(proteinGroup(x), "P62894"))

cls2 <- rep("#00000040", nrow(x))
pch2 <- rep(1, nrow(x))
cls2[grep("P02769", featureNames(x))] <- "gold4" ## BSA
cls2[grep("P00924", featureNames(x))] <- "dodgerblue" ## ENO
cls2[grep("P62894", featureNames(x))] <- "springgreen4" ## CYT
cls2[grep("P00489", featureNames(x))] <- "darkorchid2" ## PHO
pch2[grep("P02769", featureNames(x))] <- 19
pch2[grep("P00924", featureNames(x))] <- 19
pch2[grep("P62894", featureNames(x))] <- 19
pch2[grep("P00489", featureNames(x))] <- 19

nm <- NoiseModel(x)
ib.background <- subsetIBSpectra(x, protein=spks,
                                 direction = "exclude")
nm.background <- NoiseModel(ib.background)
ib.spks <- subsetIBSpectra(x, protein = spks,
                           direction="include",
                           specificity="reporter-specific")
nm.spks <- NoiseModel(ib.spks, one.to.one=FALSE, pool=TRUE)

ratios <- 10^estimateRatio(x, nm,
                           channel1="127", channel2="129",
                           protein = spks,
                           combine = FALSE)[, "lratio"]

res <- estimateRatio(x, nm,
                     channel1="127", channel2="129",
                     protein = unique(fData(x)$proteins),
                     combine = FALSE,
                     sign.level = 0.01)[, c(1, 2, 6, 8)]
res <- as.data.frame(res)
res$lratio <- -(res$lratio)

cls3 <- rep("#00000050", nrow(res))
pch3 <- rep(1, nrow(res))
cls3[grep("P02769", rownames(res))] <- "gold4" ## BSA
cls3[grep("P00924", rownames(res))] <- "dodgerblue" ## ENO
cls3[grep("P62894", rownames(res))] <- "springgreen4" ## CYT
cls3[grep("P00489", rownames(res))] <- "darkorchid2" ## PHO
pch3[grep("P02769", rownames(res))] <- 19
pch3[grep("P00924", rownames(res))] <- 19
pch3[grep("P62894", rownames(res))] <- 19
pch3[grep("P00489", rownames(res))] <- 19

rat.exp <- c(PHO = 2/2,
             ENO = 5/1,
             BSA = 2.5/10,
             CYT = 1/1)
@ %% $


\begin{figure}[!ht]
<<ibplot, dev='pdf', echo=TRUE, fig.width=5, fig.height=5, fig.keep='last'>>=
maplot(x,
       noise.model = c(nm.background, nm.spks, nm),
       channel1="127", channel2="129",
       pch = 19, col = cls2,
       main = "Spectra MA plot")
abline(h = 1, lty = "dashed", col = "grey")
legend("topright",
       c("BSA", "ENO", "CYT", "PHO"),
       pch = 19, col = c("gold4", "dodgerblue",
                   "springgreen4", "darkorchid2"),
       bty = "n", cex = .7)
@
\caption{Result from the \Biocpkg{isobar} pipeline. }
\label{fig:ibplot}
\end{figure}

\clearpage

\subsection{The \Biocpkg{synapter} package}

The \Biocpkg{synapter} \cite{synapter} package comes with a detailed
vignette that describes how to prepare the MS$^E$ data and then
process it in \R{}. Several interfaces are available provided the user
with maximum control, easy batch processing capabilities or a
graphical user interface. The conversion into \Robject{MSnSet}
instances and filter and combination thereof as well as statistical
analysis are also described.

<<synapter, eval=FALSE>>=
## open the synapter vignette
library("synapter")
synapterGuide()
@

\section{MS$^2$ spectra identification}

At the moment two packages allow the user to run peptide identifications from
within R. Each of the packages interface to an external peptide database search
tool and have more or less the same workflow, though their syntax differs:

\begin{enumerate}
\item Prepare the input data.
\item Run the search.
\item Import the search results and extract the peptides and proteins
\end{enumerate}

\subsection{X! Tandem}
Following Bioconductor 2.12 the \Biocpkg{rTANDEM} package provides the means
to run the popular X! Tandem software \cite{Craig2004}.

Using example code/data from the \Biocpkg{rTANDEM} vignette/package, the
following is an example of a typical workflow

\subsubsection{Preparation of the input data}

<<rtandem1, tidy = FALSE>>=
library(rTANDEM)
taxonomy <- rTTaxo(taxon = "yeast",
                   format = "peptide",
                   URL = system.file(
                     "extdata/fasta/scd.fasta.pro",
                     package="rTANDEM"))
param <- rTParam()
param <- setParamValue(param,
                       'protein', 'taxon',
                       value="yeast")
param <- setParamValue(param, 'list path',
                       'taxonomy information', taxonomy)
param <- setParamValue(param,
                       'list path', 'default parameters',
                       value = system.file(
                         "extdata/default_input.xml",
                         package="rTANDEM"))
param <- setParamValue(param, 'spectrum', 'path',
                       value = system.file(
                         "extdata/test_spectra.mgf",
                         package="rTANDEM"))
param <- setParamValue(param, 'output', 'xsl path',
                       value = system.file(
                         "extdata/tandem-input-style.xsl",
                         package="rTANDEM"))
param <- setParamValue(param, 'output', 'path',
                       value = paste(getwd(),
                         "output.xml", sep="/"))
@


\subsubsection{Performing the search}

The analysis is run using the \Rfunction{tandem} function (see also the
\Rfunction{rtandem} function), which returns the results data file path (only
the file name is displayed below).

<<rtandem2>>=
resultPath <- tandem(param)
basename(resultPath)
@

\subsubsection{Import and analyse results}

<<rtandem3>>=
res <- GetResultsFromXML(resultPath)
## the inferred proteins
proteins <- GetProteins(res,
                        log.expect = -1.3,
                        min.peptides = 2)
proteins[, -(4:5), with = FALSE]
## the identified peptides for YFR053C
peptides <- GetPeptides(protein.uid = 1811,
                        results = res,
                        expect = 0.05)
peptides[, c(1:4, 9, 10:16), with = FALSE]
@

More details are provided in the vignette available with
\Rfunction(vignette("rTANDEM")), for instance the extraction of degenerated
peptides, i.e. peptides found in multiple proteins.


\bigskip

The \Biocpkg{shinyTANDEM} package offers a web-based graphical
interface to \Biocpkg{rTANDEM}.

\subsection{MS-GF+}
With the release of Bioconductor 3.0 the \Biocpkg{MSGFplus} package has
provided an interface to MS-GF+ \cite{Kim:2008go, Kim:2010ks}. The package
vignette describe in detail the different ways an MS-GF+ analysis can be
initiated and only a simple example will be given here:

\subsubsection{Preparation of the input data}
<<msgf1>>=
library(MSGFplus)
## Create a parameter object with a set of parameters
param <- msgfPar(database = system.file('extdata',
                                        'milk-proteins.fasta',
                                        package='MSGFplus'),
                 tolerance = '10 ppm',
                 enzyme = 'Trypsin')

## Add parameters after creation
instrument(param) <- 'QExactive'
tda(param) <- TRUE

## Add expected modifications
mods(param)[[1]] <- msgfParModification('Carbamidomethyl',
                                        composition = 'C2H3N1O1',
                                        residues = 'C',
                                        type = 'fix',
                                        position = 'any')
nMod(param) <- 2    # Number of allowed modifications per peptide

## Get a summary of your parameters
show(param)
@

\subsubsection{Performing the search}
Initiating the search is done using the \Rfunction{runMSGF} method. As a minimum
it takes a parameter object and a list of raw data files and performs the search
for each data file in sequence. More specialised operations are also possible
such as running it asynchronously, but interested readers should refer to the
\Biocpkg{MSGFplus} vignette for additional information.

The first time a search is initialised the MS-GF+ code is downloaded, so be sure
to have an active internet connection (only applies to the first time a search
is run).

<<msgfplus2, eval=FALSE>>=
result <- runMSGF(param, 'path/to/a/rawfile.mzML')
@

\subsubsection{Import and analyse results}
By default MSGFplus imports the results automatically using \Biocpkg{mzID}. If
only one file was analysed, the return value is an mzID object; if multiple
files are analysed at once the return value is an mzIDCollection object.

If \texttt{import=FALSE} the results are not imported and can be accessed at a
later time using the \Biocpkg{mzID} package (see section~\ref{subsec:mzID} on
page~\pageref{subsec:mzID}).

\subsubsection{Running MS-GF+ through a GUI}
\Biocpkg{MSGFplus} comes with a sister package, \Rpackage{MSGFgui},
which provide a graphic interface to setting up and running MS-GF+
through \R. Besides facilitating MS-GF+ analyses, which is arguably
just as easy from the command line, it provides an intuitive way to
investigate and evaluate the resulting identification data.


\begin{figure}[!ht]
  \centering
    \includegraphics[width=.6\textwidth]{figure/MSGFgui.png}
    \caption{A screenshot of MSGFgui}
    \label{fig:MSGFgui}
\end{figure}

Figure~\ref{fig:MSGFgui} shows an example of using \Rpackage{MSGFgui}. It is
possible to gradually drill down in the results starting from the protein level
and ending at the raw spectrum level. mzIdentML files already created with
MS-GF+ (using \Biocpkg{MSGFplus} or in other ways) can easily be imported into
the gui to take advantage of the visualisation features, and results can be
exported as either rds (for R), xlsx (for excel) or txt (for everything else)
files.




\subsection{Post-search Filtering of MS/MS IDs Using \Biocpkg{MSnID}}
\emph{The main purpose of \Biocpkg{MSnID} package is to make sure that the peptide and protein identifications resulting from MS/MS searches are sufficiently confident for a given application.}
MS/MS peptide and protein identification is a process that prone to uncertanities.
A typical and currently most reliable way to quantify uncertainty in the list of identify spectra, peptides or proteins relies on so-called decoy database. For bottom-up (i.e. involving protein digestion) approaches a common way to construct a decoy database is simple inversion of protein amino-acid sequences. If the spectrum matches to normal protein sequence it can be true or false match. Matches to decoy part of the database are false only (excluding the palindromes). Therefore the false discovery rate (FDR) of identifications can be estimated as ratio of hits to decoy over normal parts of the protein sequence database. There are multiple levels of identification that FDR can be estimated for. First, is at the level of peptide/protein- to-spectrum matches. Second is at the level of unique peptide sequences. Note, true peptides tend to be identified by more then one spectrum. False peptide tend to be sporadic. Therefore, after collapsing the redundant peptide identifications from multiple spectra to the level of unique peptide sequence, the FDR typically increases. The extend of FDR increase depends on the type and complexity of the sample. The same trend is true for estimating the identification FDR at the protein level. True proteins tend to be identified with multiple peptides, while false protein identifications are commonly covered only by one peptide. Therefore FDR estimate tend to be even higher for protein level compare to peptide level.
The estimation of the FDR is also affected by the number of LC-MS (runs) datasets in the experiment. Again, true identifications tend to be more consistent from run to run, while false are sporadic. After collapsing the redundancy across the runs, the number of true identification reduces much stronger compare to false identifications. Therefore, the peptide and protein FDR estimates need to be re-evaluated.
The main objective of the MSnID package is to provide convenience tools for handling tasks on estimation of FDR, defining and optimizing the filtering criteria and ensuring confidence in MS/MS identification data. The user can specify the criteria for filtering the data (e.g. goodness or p-value of matching of experimental and theoretical fragmentation mass spectrum, deviation of theoretical from experimentally measured mass, presence of missed cleavages in the peptide sequence, etc), evaluate the performance of the filter judging by FDRs at spectrum, peptide and protein levels, and finally optimize the filter to achieve the maximum number of identifications while not exceeding maximally allowed FDR upper threshold.
\subsubsection{Starting Project \& Importing Data}
To start a project one have to specify a directory. Currently the only use of the directory is for storing cached results.
<<MSnIDstart>>=
library("MSnID")
msnid <- MSnID(".")
@
Data can imported as \Rcode{data.frame} or read from mzIdentML file.
<<MSnIDdataImport>>=
PSMresults <- read.delim(system.file("extdata", "human_brain.txt",
                                     package="MSnID"),
                         stringsAsFactors=FALSE)
psms(msnid) <- PSMresults
show(msnid)

mzids <- system.file("extdata", "c_elegans.mzid.gz", package="MSnID")
msnid <- read_mzIDs(msnid, mzids)
show(msnid)
@

\subsubsection{Analysis of Peptide Sequences}
A particular properties of peptide sequences we are interested in are
\begin{enumerate}
    \item irregular cleavages at the termini of the peptides and
    \item missing cleavage site within the peptide sequences.
\end{enumerate}
The default regular expressions of valid and missed cleavage
patterns correspond to trypsin.
Counting the number of irregular cleavage termimi (0,1 or 2) in peptides
sequence creates a new column \texttt{numIrregCleavages}. Counting the number of missed cleavages in peptides sequence creates a new
column \texttt{numMissCleavages}.
<<MSnIDsequence>>=
msnid <- assess_termini(msnid, validCleavagePattern="[KR]\\.[^P]")
msnid <- assess_missed_cleavages(msnid, missedCleavagePattern="[KR](?=[^P$])")
@
Now the object has two more columns, \texttt{numIrregCleavages} and
\texttt{numMissCleavages}, evidently corresponding to the number
of termini with irregular cleavages and number of missed cleavages
within the peptide sequence. The figure below shows that peptides with 2 or more missed cleavages are likely to be false identifications.
<<MSnIDmissedCleavagesPlot, dev='pdf', fig.width=8, fig.height=4, out.width='.7\\textwidth'>>=
pepCleav <- unique(psms(msnid)[,c("numMissCleavages", "isDecoy", "peptide")])
pepCleav <- as.data.frame(table(pepCleav[,c("numMissCleavages", "isDecoy")]))
library("ggplot2")
ggplot(pepCleav, aes(x=numMissCleavages, y=Freq, fill=isDecoy)) +
    geom_bar(stat='identity', position='dodge') +
    ggtitle("Number of Missed Cleavages")
@

\subsubsection{Defining the Filter}
The criteria that will be used for filtering the MS/MS data has to be present
in the \Robject{MSnID} object. We will use -log10 transformed MS-GF+
Spectrum E-value, reflecting the goodness of match experimental and
theoretical fragmentation patterns as one the filtering criteria.
Let's store it under the "msmsScore" name. The score density distribution
shows that it is a good discriminant between non-decoy (red)
and decoy hits (green).
\\
For alternative MS/MS search engines refer to the engine-specific manual for
the names of parameters reflecting the quality of MS/MS spectra matching.
Examples of such parameters are \Rcode{E-Value} for X!Tandem
and \Rcode{XCorr} and \Rcode{$\Delta$Cn2} for SEQUEST.
\\
As a second criterion we will be using the absolute mass measurement
error (in ppm units) of the parent ion. The mass measurement errors tend to
be small for non-decoy (enriched with real identificaiton) hits (red line) and
is effectively uniformly distributed for decoy hits.
<<MSnIDfilteringCriteria>>=
msnid$msmsScore <- -log10(msnid$`MS-GF:SpecEValue`)
msnid$absParentMassErrorPPM <- abs(mass_measurement_error(msnid))
@
MS/MS fiters are handled by a special \Rclass{MSnIDFilter} class objects.
Individual filtering criteria can be set by name
(that is present in \Rcode{names(msnid)}), comparison operator (>, <, = , ...)
defining if we should retain hits with higher or lower given the threshold and
finally the threshold value itself. The filter below set in such a way that retains only those matches that has less then 5 ppm of parent ion mass measurement error and more the $10^7$ MS-GF:SpecEValue.
<<MSnIDsettingFilter>>=
filtObj <- MSnIDFilter(msnid)
filtObj$absParentMassErrorPPM <- list(comparison="<", threshold=5.0)
filtObj$msmsScore <- list(comparison=">", threshold=8.0)
show(filtObj)
@
The stringency of the filter can be evaluated at different levels.
<<MSnIDfilterAssessment>>=
evaluate_filter(msnid, filtObj, level="PSM")
evaluate_filter(msnid, filtObj, level="peptide")
evaluate_filter(msnid, filtObj, level="accession")
@

\subsubsection{Optimizing the Filter}
The threshold values in the example above are not necessarily optimal and set
just be in the range of probable values. Filters can be optimized to ensure
maximum number of identifications (peptide-to-spectrum matches,
unique peptide sequences or proteins) within a given FDR upper limit.
\\
First, the filter can be optimized simply by stepping through
individual parameters and their combinations. The idea has been described in
\cite{Piehowski2013a}. The resulting \Robject{MSnIDFilter} object can be
used for final data filtering or can be used as a good starting parameters for
follow-up refining optimizations with more advanced algorithms.
<<MSnIDfilterOptimization1>>=
filtObj.grid <- optimize_filter(filtObj, msnid, fdr.max=0.01,
                                method="Grid", level="peptide",
                                n.iter=500)
show(filtObj.grid)
@
The resulting \Rcode{filtObj.grid} can be further fine tuned with such
optimization routines as simulated annealing or Nelder-Mead optimization.
<<MSnIDfilterOptimization2>>=
filtObj.nm <- optimize_filter(filtObj.grid, msnid, fdr.max=0.01,
                                method="Nelder-Mead", level="peptide",
                                n.iter=500)
show(filtObj.nm)
@
Evaluate non-optimized and optimized filters.
<<MSnIDfilterAssessment2>>=
evaluate_filter(msnid, filtObj, level="peptide")
evaluate_filter(msnid, filtObj.grid, level="peptide")
evaluate_filter(msnid, filtObj.nm, level="peptide")
@
Finally applying filter to remove predominantly false identifications.
<<MSnIDapplyFilter>>=
msnid <- apply_filter(msnid, filtObj.nm)
show(msnid)
@
Removing hits to decoy and contaminant sequences using the same
\Rcode{apply\_filter} method.
<<MSnIDremovingDecoyAndContaminants>>=
msnid <- apply_filter(msnid, "isDecoy == FALSE")
show(msnid)
msnid <- apply_filter(msnid, "!grepl('Contaminant',accession)")
show(msnid)
@

\subsubsection{Interface with Other Bioconductor Packages}
One can extract the entire PSMs tables as \Rcode{data.frame} or \Rcode{data.table}
<<MSnIDgetDataOut1>>=
psm.df <- psms(msnid)
psm.dt <- as(msnid, "data.table")
@
If only interested in the non-redundant list of confidently identified
peptides or proteins
<<MSnIDgetDataOut2>>=
peps <- peptides(msnid)
head(peps)
prots <- accessions(msnid)
head(prots)
prots <- proteins(msnid) # may be more intuitive then accessions
head(prots)
@
The \Biocpkg{MSnID} package is aimed at providing convenience functionality
to handle MS/MS identifications. Quantification \textit{per se} is outside of
the scope of the package. The only type of quantitation that can be seamlessly
tied with MS/MS identification analysis is so-called
\emph{spectral counting} approach. In such an approach a peptide abundance is
considered to be directly proportional to the number of matched MS/MS spectra.
In its turn protein abunance is proportional to the sum of the number of
spectra of the matching peptides. The \Rclass{MSnID} object can be converted
to an \Rclass{MSnSet} object defined in \Biocpkg{MSnbase} that extends generic
Bioconductor \Rclass{eSet} class to quantitative proteomics data.
The spectral count data can be analyzed with \Biocpkg{msmsEDA},
\Biocpkg{msmsTests} or \Biocpkg{DESeq} packages.
<<MSnIDconvertingToMSnSet>>=
msnset <- as(msnid, "MSnSet")
library("MSnbase")
head(fData(msnset))
head(exprs(msnset))
@
Note, the convertion from \Robject{MSnID} to \Robject{MSnSet} uses peptides
as features. The number of redundant peptide observations represent so-called
spectral count that can be used for rough quantitative analysis. Summing of
all of the peptide counts to a proteins level can be done with
\Rcode{combineFeatures} function from \Biocpkg{MSnbase} package.
<<MSnIDsummingPeptidesToProteins>>=
msnset <- combineFeatures(msnset,
                            fData(msnset)$accession,
                            redundancy.handler="unique",
                            fun="sum",
                            cv=FALSE)
head(fData(msnset))
head(exprs(msnset))
@

% clean-up
<<eval=TRUE, echo=FALSE, results='hide'>>=
unlink(".Rcache", recursive=TRUE)
@






\section{Quality control}\label{sec:qc}

Quality control (QC) is an essential part of any high throughput data
driven approach. Bioconductor has a rich history of QC for various
genomics data and currently two packages support proteomics QC.

\Biocpkg{proteoQC} provides a dedicated a dedicated pipeline that will
produce a dynamic and extensive html report. It uses the
\Biocpkg{rTANDEM} package to automate the generation of identification
data and uses information about the experimental/replication design.


The \Biocpkg{qcmetrics} package is a general framework to define QC
metrics and bundle them together to generate html or pdf reports. It
provides some ready made metrics for MS data and $^{15}$N labelled
data.

\section{Annotation}\label{sec:annot}

In this section, we briefly present some \Bioconductor{} annotation
infrastructure.

We start with the \Biocpkg{hpar} package, an interface to the
\textit{Human Protein Atlas} \cite{Uhlen2005, Uhlen2010}, to retrieve
subcellular localisation information for the \texttt{ENSG00000002746}
ensemble gene.

<<annot1, cache=FALSE>>=
id <- "ENSG00000002746"
library("hpar")
getHpa(id, "SubcellularLoc")
@

Below, we make use of the human annotation package
\Biocannopkg{org.Hs.eg.db} and the Gene Ontology annotation package
\Biocannopkg{GO.db} to retrieve the same information as above.

<<annot2, cache=FALSE, warning = FALSE>>=
library(org.Hs.eg.db)
library(GO.db)
ans <- select(org.Hs.eg.db,
              keys = id, columns = c("ENSEMBL", "GO", "ONTOLOGY"),
              keytype = "ENSEMBL")
ans <- ans[ans$ONTOLOGY == "CC", ]
ans
sapply(as.list(GOTERM[ans$GO]), slot, "Term")
@

Finally, this information can also be retrieved from on-line databases
using the \Biocpkg{biomaRt} package \cite{Durinck2005}.

<<annot3, cache=TRUE>>=
library("biomaRt")
ensembl <- useMart("ensembl",dataset="hsapiens_gene_ensembl")
efilter <- "ensembl_gene_id"
eattr <- c("go_id", "name_1006", "namespace_1003")
bmres <- getBM(attributes=eattr, filters = efilter, values = id, mart = ensembl)
bmres[bmres$namespace_1003 == "cellular_component", "name_1006"]
@ %% $

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Section
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\section{Other packages}\label{sec:packages}

\subsection{\Bioconductor{} packages}


<<protpacks, echo=FALSE, warning=FALSE, cache=TRUE>>=
# biocVersion has to be of type character
biocv <- as.character(biocVersion())

pkTab <- list(Proteomics = proteomicsPackages(biocv),
              MassSpectrometry = massSpectrometryPackages(biocv),
              MassSpectrometryData = massSpectrometryDataPackages(biocv))
@

This section provides a complete list of packages available in the
relevant \Bioconductor{} version \Sexpr{biocv} (as of \today)
\textit{biocView}\footnote{\url{http://www.bioconductor.org/packages/devel/BiocViews.html}}
categories.  Tables \ref{tab:prot}, \ref{tab:ms} and \ref{tab:msdata}
represent the packages for the \texttt{Proteomics}
(\Sexpr{nrow(pkTab[["Proteomics"]])} packages),
\texttt{MassSpectrometry} (\Sexpr{nrow(pkTab[["MassSpectrometry"]])}
packages) and \texttt{MassSpectrometryData}
(\Sexpr{nrow(pkTab[["MassSpectrometryData"]])} experiment packages)
categories.

<< xtabpkg, echo=FALSE, message=FALSE>>=
library("xtable")
@

<<protstab, echo=FALSE, results='asis'>>=
t1 <- xtable(pkTab[["Proteomics"]],
             caption = "Packages available under the \\texttt{Proteomics} \\textit{biocViews} category.",
             table.placement = "thb",
             label = "tab:prot")
align(t1) <- c("l", "l", "p{10cm}", "l")
print(t1,
      include.rownames = FALSE,
      floating = FALSE,
      tabular.environment = 'longtable',
      size = "scriptsize")
@

<<mstab, echo=FALSE, results='asis'>>=
t2 <- xtable(pkTab[["MassSpectrometry"]],
             caption = "Packages available under the \\texttt{MassSpectrometry} \\textit{biocViews} category.",
             table.placement = "thb",
             label = "tab:ms")
align(t2) <- c("l", "l", "p{10cm}", "l")
print(t2,
      include.rownames = FALSE,
      floating = FALSE,
      tabular.environment = 'longtable',
      size = "scriptsize")

@

<<msdatatab, echo=FALSE, results='asis'>>=
t3 <- xtable(pkTab[["MassSpectrometryData"]],
             caption = "Experimental Packages available under the \\texttt{MassSpectrometryData} \\textit{biocViews} category.",
             table.placement = "thb",
             label = "tab:msdata")
align(t3) <- c("l", "l", "p{10cm}", "l")
print(t3,
      include.rownames = FALSE,
      floating = FALSE,
      tabular.environment = 'longtable',
      size = "scriptsize")
@

The tables can easily be generated with the
\Rfunction{proteomicsPackages}, \Rfunction{massSpectrometryPackages}
and \Rfunction{massSpectrometryDataPackages} functions. The respective
package tables can then be interactively explored using the
\Rfunction{display} function.

<<pkgs, eval=FALSE>>=
pp <- proteomicsPackages()
display(pp)
@

\subsection{Other CRAN packages}

<<cntCRAN, echo=FALSE>>=
X <- readLines("http://cran.r-project.org/web/views/ChemPhys.html")
x2 <- grep("Related links:", X)
x1 <- grep("CRAN packages:", X)
np <- length(grep("../packages/", X[x1:x2]))
@

The CRAN task view on Chemometrics and Computational
Physics\footnote{\url{http://cran.r-project.org/web/views/ChemPhys.html}}
is another useful ressource listing \Sexpr{np} packages, including a
set of packages for mass spectrometry and proteomics, some of which
are illustrated in this document.

\begin{description}
\item[\CRANpkg{MALDIquant}] provides tools for quantitative analysis of
  MALDI-TOF mass spectrometry data, with support for baseline
  correction, peak detection and plotting of
  mass spectra \\
  (\url{http://cran.r-project.org/web/packages/MALDIquant/index.html}).
\item[\CRANpkg{OrgMassSpecR}] is for organic/biological mass spectrometry, with
  a focus on graphical display, quantification using stable isotope
  dilution, and protein hydrogen/deuterium exchange
  experiments \\
  (\url{http://cran.r-project.org/web/packages/OrgMassSpecR/index.html}).
\item[\CRANpkg{FTICRMS}] provides functions for Analyzing Fourier Transform-Ion
  Cyclotron
  Resonance Mass Spectrometry Data \\
  (\url{http://cran.r-project.org/web/packages/FTICRMS/index.html}).
\item[\CRANpkg{titan}] provides a GUI to analyze mass spectrometric data on the
  relative abundance
  of two substances from a titration series \\
  (\url{http://cran.r-project.org/web/packages/titan/index.html}).
\item[\CRANpkg{digeR}] provides a GUI interface for analysing 2D DIGE data. It
  allows to perform correlation analysis, score plot, classification,
  feature selection and power analysis for
  2D DIGE experiment data. \\
  (\url{http://cran.r-project.org/web/packages/digeR/index.html})
\item[\CRANpkg{protViz}] helps with quality checks, visualizations and analysis
  of mass spectrometry data, coming from proteomics experiments. The
  package is developed, tested and used at the Functional Genomics
  Center Zurich. \\
  (\url{http://cran.r-project.org/web/packages/protViz/index.html})
\end{description}

\bigskip

Suggestions for additional \R{} packages are welcome and will be added
to the vignette.  Please send suggestions and possibly a short
description and/or a example utilisation with code to
\url{lg390@cam.ac.uk}. The only requirement is that the package must
be available on an official package channel (CRAN, \Bioconductor{},
R-forge, Omegahat), i.e. not only available through a personal web
page.

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Section
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Session information}\label{sec:sessionInfo}

All software and respective versions used in this document, as
returned by \Rfunction{sessionInfo()} are detailed below.

<<sessioninfo, results='asis', echo=FALSE, echo=FALSE>>=
toLatex(sessionInfo(), locale = FALSE)
@

\bibliography{RforProteomics}

\end{document}
