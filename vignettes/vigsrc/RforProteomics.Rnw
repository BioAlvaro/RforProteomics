n\VignetteEngine{knitr}
%\VignetteIndexEntry{Using R for proteomics data analysis}
%\VignetteKeywords{Bioinformatics, proteomics, mass spectrometry, tutorial, data}
%\VignettePackage{RforProteomics}

\documentclass{article}

\usepackage{longtable}

<<biocstyle, eval=TRUE, echo=FALSE, results="asis">>=
BiocStyle::latex()
@

\author{
  Laurent Gatto\footnote{\email{lg390@cam.ac.uk}, \url{http://cpu.sysbiol.cam.ac.uk}}~,
  Vlad Petyuk,
  Thomas Lin Pedersen,
  Sebastian Gibb}

\title{Using \R{} and \Bioconductor{} for Proteomics Data Analysis}

\begin{document}

\maketitle

<<env0, echo = FALSE, warning = FALSE, message=FALSE>>=
suppressPackageStartupMessages(library("BiocInstaller"))
## suppressPackageStartupMessages(library("parallel"))
suppressPackageStartupMessages(library("MSnbase"))
suppressPackageStartupMessages(library("mzID"))
suppressPackageStartupMessages(library("rpx"))
suppressPackageStartupMessages(library("isobar"))
suppressPackageStartupMessages(library("MALDIquant"))
suppressPackageStartupMessages(library("MALDIquantForeign"))
suppressPackageStartupMessages(library("IPPD"))
suppressPackageStartupMessages(library("rols"))
suppressPackageStartupMessages(library("hpar"))
suppressPackageStartupMessages(library("BRAIN"))
suppressPackageStartupMessages(library("org.Hs.eg.db"))
suppressPackageStartupMessages(library("GO.db"))
suppressPackageStartupMessages(library("Rdisop"))
suppressPackageStartupMessages(library("rTANDEM"))
suppressPackageStartupMessages(library("MSGFplus"))
suppressPackageStartupMessages(library("MSGFgui"))
@

<<'setup', include = FALSE, cache = FALSE>>=
library("knitr")
opts_chunk$set(tidy.opts =
                   list(width.cutoff = 50,
                   tidy = FALSE),
               fig.align = 'center',
               stop_on_error = 1L)
options(width = 60)
@
%% $

%% Abstract and keywords %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\vskip 0.3in minus 0.1in
\hrule
\begin{abstract}
  This vignette shows and executes the code presented in the
  manuscript \textit{Using \R{} for proteomics data analysis}.  It also
  aims at being a general overview for users who wish to explore the
  \R{} environment and programming language for the analysis of
  proteomics data.
\end{abstract}

\textit{Keywords}: proteomics, mass spectrometry, tutorial.
\vskip 0.1in minus 0.05in
\hrule
\vskip 0.2in minus 0.1in
\vspace{10mm}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\tableofcontents

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Section
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}\label{sec:intro}

This document illustrates some existing \R{} infrastructure for the
analysis of proteomics data.  It presents the code for the use cases
taken from \cite{R4prot2013,Gatto:2015}. A pre-print of
\cite{R4prot2013} available on
arXiv\footnote{\url{http://arxiv.org/abs/1305.6559}} and
\cite{Gatto:2015} is open
access\footnote{\url{http://onlinelibrary.wiley.com/doi/10.1002/pmic.201400392/full}}.

There are however numerous additional \R{} resources distributed by the
\Bioconductor{}\footnote{\url{http://www.bioconductor.org}} and
CRAN\footnote{\url{http://cran.r-project.org/web/packages/}}
repositories, as well as packages hosted on personal websites. Section
\ref{sec:packages} on page \pageref{sec:packages} tries to provide a
wider picture of available packages, without going into details.

\subsection{General \R{} resources}\label{sec:rres}

The reader is expected to have basic \R{} knowledge to find the document
helpful. There are numerous \R{} introductions freely available, some of
which are listed below.

From the \R{} project web-page:
\begin{itemize}
\item \textbf{An Introduction to R} is based on the former \textit{Notes on R},
  gives an introduction to the language and how to use R for doing statistical
  analysis and graphics.
  [\href{http://cran.r-project.org/doc/manuals/R-intro.html}{browse HTML} |
    \href{http://cran.r-project.org/doc/manuals/R-intro.pdf}{download PDF}]
  \item Several introductory tutorials in the
    \href{http://cran.r-project.org/other-docs.html}{contributed
      documentation} section.
  \item The \texttt{TeachingMaterial}
    repository\footnote{\href{https://github.com/lgatto/TeachingMaterial}{https://github.com/lgatto/TeachingMaterial}}
    contains several sets of slides and vignettes about \R{}
    programming.
\end{itemize}

Relevant background on the \R{} software and its application to
computational biology in general and proteomics in particular can also
be found in \cite{R4prot2013}. For details about the \Bioconductor{}
project, the reader is referred to \cite{Gentleman2004}.

\subsection{Bioconductor resources}\label{sec:biocres}


The Bioconductor offers many educational resources on its help page
\url{http://bioconductor.org/help/}, in addition the package's
vignettes (vignettes are a requirement for Bioconductor packages). We
want to draw the attention to the Bioconductor work flows that offer a
cross-package overview about a specific topic. In particular, there is
now a \textit{Mass spectrometry and proteomics data
  analysis}\footnote{\url{http://bioconductor.org/help/workflows/proteomics/}}
work flow.

\subsection{Getting help}

All \R{} packages come with ample documentation. Every command
(function, class or method) a user is susceptible to use is
documented. The documentation can be accessed by preceding the command
by a \texttt{?} in the \R{} console. For example, to obtain help about
the \Rfunction{library} function, that will be used in the next
section, one would type \Rfunction{?library}. In addition, all
\Bioconductor{} packages come with at least one vignette (this document
is the vignette that comes with the \Biocpkg{RforProteomics}
package), a document that combines text and \R{} code that is executed
before the pdf is assembled. To look up all vignettes that come with a
package, say \Biocpkg{RforProteomics} and then open the vignette of
interest, one uses the \Rfunction{vignette} function as illustrated
below. More details can be found in \Rfunction{?vignette}.

<<vignette1, echo = TRUE, eval = FALSE>>=
## list all the vignettes in the RforProteomics package
vignette(package = "RforProteomics")
## Open the vignette called RforProteomics
vignette("RforProteomics", package = "RforProteomics")
## or just
vignette("RforProteomics")
@


\R{} has several mailing
lists\footnote{\url{http://www.r-project.org/mail.html}}. The most
relevant here being the main \texttt{R-help} list, \textit{for
  discussion about problem and solutions using \R{}}, ideal for
general \R{} content and is not suitable for bioinformatics or
proteomics questions. \Bioconductor{} also offers several resources
dedicated to bioinformatics matters and \Bioconductor{} packages, in
particular the main \Bioconductor{} support
forum\footnote{\url{https://support.bioconductor.org/}} for
Bioconductor-related queries. A dedicated \Biocpkg{RforProteomics}
Google
group\footnote{\url{https://groups.google.com/forum/\#!forum/rbioc-sig-proteomics}}
also welcomes questions/comments/annoucements related to \R{} and
mass-spectrometry/proteomics, although the Bioconductor forum is the
preferred channel.

It is advised to read and comply to the posting guides
(\href{http://www.r-project.org/posting-guide.html}{here} and
\href{http://bioconductor.org/help/mailing-list/posting-guide/}{here})
to maximise the chances to obtain good responses. It is important to
specify the software versions using the \Rfunction{sessionInfo()}
functions (see an example output at the end of this document, on page
\pageref{sec:sessionInfo}). It the question involves some code, make
sure to isolate the relevant portion and report it with your question,
trying to make your code/example
reproducible\footnote{\url{https://github.com/hadley/devtools/wiki/Reproducibility}}.

\subsection{Installation}

The package should be installed using as described below:

<<installation, eval = FALSE>>=
## only first time you install Bioconductor packages
source("http://www.bioconductor.org/biocLite.R")
## else
library("BiocInstaller")
biocLite("RforProteomics")
@

To install all dependencies and reproduce the code in the vignette,
replace the last line in the code chunk above with:)

<<installation2, eval = FALSE>>=
biocLite("RforProteomics", dependencies = TRUE)
@

Finally, the package can be loaded with

<<loadR4Prot, warning=FALSE>>=
library("RforProteomics")
@

See also the \Biocpkg{RforProteomics} web
page\footnote{\url{http://lgatto.github.io/RforProteomics/}} for more
information on installation.

\subsection{External dependencies}

Some packages used in the document depend on external libraries that
need to be installed prior to the \R{} packages:

\begin{description}
\item[\Biocpkg{mzR}] depends on the Common Data
  Format\footnote{\url{http://cdf.gsfc.nasa.gov/}} (CDF) to CDF-based
  raw mass-spectrometry data. On Linux, the \texttt{libcdf} library is
  required.  On Debian-based systems, for instance, one needs to
  install the \texttt{libnetcdf-dev} package.
\item[\Biocpkg{IPPD}] (and others) depend on the \CRANpkg{XML}
  package which requires the \texttt{libxml2} infrastructure on
  Linux. On Debian-based systems, one needs to install
  \texttt{libxml2-dev}.
\item [\Biocpkg{biomaRt}] performs on-line requests using the
  \texttt{curl}\footnote{\url{http://curl.haxx.se/}}
  infrastructure. On Debian-based systems, you one needs to install
  \texttt{libcurl-dev} or \texttt{libcurl4-openssl-dev}.
  \item[\Biocpkg{MSGFplus}] Is based on the MS-GF+ java program and thus
  requires Java 1.7\footnote{\url{https://java.com}} in order to work.
\end{description}

\subsection{Obtaining the code}

The code in this document describes all the examples presented in
\cite{R4prot2013} and can be copy, pasted and executed. It is however
more convenient to have it in a separate text file for better
interaction with \R{} (using
ESS\footnote{\url{http://ess.r-project.org/}} for Emacs or
RStudio\footnote{\url{http://rstudio.org/}} for instance) to easily
modify and explore it. This can be achieved with the
\Rfunction{Stangle} function. One needs the Sweave source of this
document (a document combining the narration and the \R{} code) and the
\Rfunction{Stangle} then specifically extracts the code chunks and
produces a clean \R{} source file. If the package is installed, the
following code chunk will create a \texttt{RforProteomics.R} file in
your working directory containing all the annotated source code
contained in this document.

<<stangle, eval=TRUE, tidy=FALSE, error=FALSE>>=
## gets the vignette source
rnwfile <- system.file("doc/vigsrc/RforProteomics.Rnw",
                       package = "RforProteomics")
## produces the R file in the working directory
library("knitr")
purl(rnwfile, quiet = TRUE)
@ %% $

Alternatively, you can obtain the \texttt{Rnw} file on the github page
\url{https://github.com/lgatto/RforProteomics/blob/master/inst/doc/vigsrc/RforProteomics.Rnw}.

\subsection{Prepare the working environment}

The packages that we will depend on to execute the examples will be
loaded in the respective sections. Here, we pre-load packages that
provide general functionality used throughout the document.

<<env>>=
library("RColorBrewer") ## Color palettes
library("ggplot2")  ## Convenient and nice plotting
library("reshape2") ## Flexibly reshape data
@

\section{Data standards and input/output}

\subsection{The mzR package}\label{sec:mzr}

\subsubsection{Raw MS data}

The \Biocpkg{mzR} package \cite{Chambers2012} provides a unified
interface to various mass spectrometry open formats.  This code chunk,
taken from the \Rfunction{openMSfile} documentation, illustrated how
to open a connection to an raw data file. The example \texttt{mzML}
data is taken from the \Biocexptpkg{msdata} data package.  The code
below would also be applicable to an \texttt{mzXML}, \texttt{mzData}
or \texttt{netCDF} file.

<<mzr>>=
## load the required packages
library("mzR") ## the software package
library("msdata") ## the data package
## below, we extract the releavant example file
## from the local 'msdata' installation
filepath <- system.file("microtofq", package = "msdata")
file <- list.files(filepath, pattern="MM14.mzML",
                   full.names=TRUE, recursive = TRUE)
## creates a commection to the mzML file
mz <- openMSfile(file)
## demonstraction of data access
basename(fileName(mz))
isInitialized(mz)
runInfo(mz)
instrumentInfo(mz)
## once finished, it is good to explicitely
## close the connection
close(mz)
@

\Biocpkg{mzR} is used by other packages, like \Biocpkg{MSnbase}
\cite{Gatto2012}, \Biocpkg{TargetSearch} \cite{TargetSearch2009} and
\Biocpkg{xcms} \cite{Smith2006, Benton2008, Tautenhahn2008}, that
provide a higher level abstraction to the data.

\subsubsection{Identification data}

The \Biocpkg{mzR} package also provides very fast access to
\texttt{mzIdentML} data by leveraging proteowizard's \texttt{C++}
parser.

<<mzrid>>=
file <- system.file("mzid", "Tandem.mzid.gz", package="msdata")
mzid <- openIDfile(file)
mzid
@

Once and \Robject{mzRident} identification file handle has been
established, various data and metadata can be extracted, as
illustrated below.

<<mzrid2>>=
softwareInfo(mzid)
enzymes(mzid)
names(psms(mzid))
head(psms(mzid))[, 1:13]
@

\subsection{Handling MS$^2$ identification data with \Biocpkg{mzID}}
\label{subsec:mzID}

The \Biocpkg{mzID} package allows to load and manipulate MS$^2$ data
in the \texttt{mzIdentML} format. The main \Rfunction{mzID} function
reads such a file and constructs an instance of class \Robject{mzID}.

<<mzid1>>=
library("mzID")
id <- mzID("http://psi-pi.googlecode.com/svn/trunk/examples/1_1examples/55merge_tandem.mzid")
id
@

Multiple files can be parsed in one go, possibly in parallel if the
environment supports it. When this is done an mzIDCollection object
is returned:

<<mzid2>>=
ids <- mzID(c(
    "http://psi-pi.googlecode.com/svn/trunk/examples/1_1examples/55merge_tandem.mzid",
    "http://psi-pi.googlecode.com/svn/trunk/examples/1_1examples/55merge_omssa.mzid"))
ids
@

Peptides, scans, parameters, \ldots can be extracted with the
respective \Rfunction{pepetides}, \Rfunction{scans},
\Rfunction{parameters}, \ldots functions. The \Robject{mzID} object
can also be converted into a \texttt{data.frame} using the
\Rfunction{flatten} function.

<<flatid>>=
fid <- flatten(id)
names(fid)
dim(fid)
@


\section{Raw data abstraction with \Robject{MSnExp} objects}

\Biocpkg{MSnbase} \cite{Gatto2012} provides base functions and
classes for MS-based proteomics that allow facile data and meta-data
processing, manipulation and plotting (see for instance figure
\ref{fig:msnexp} on page \pageref{fig:msnexp}).

<<msnexp>>=
library("MSnbase")
## uses a simple dummy test included in the package
mzXML <- dir(system.file(package="MSnbase",dir="extdata"),
             full.name=TRUE,
             pattern="mzXML$")
basename(mzXML)
## reads the raw data into and MSnExp instance
raw <- readMSData(mzXML, verbose = FALSE)
raw
## Extract a single spectrum
raw[[3]]
@
%% $

\begin{figure}[!ht]
<<msnexpPlot, dev='pdf', echo=TRUE, fig.width=5, fig.height=5, fig.keep='all', out.width='.48\\linewidth'>>=
plot(raw, full=TRUE)
plot(raw[[3]], full=TRUE, reporters=iTRAQ4)
@
\caption{The \Rfunction{plot} method can be used on experiments,
  i.e. spectrum collections (top), or individual spectra (bottom). }
\label{fig:msnexp}
\end{figure}

\clearpage

\subsection{\texttt{mgf} read/write support}

Read and write support for data in the
\texttt{mgf}\footnote{\url{http://www.matrixscience.com/help/data_file_help.html\#GEN}}
and \texttt{mzTab}\footnote{\url{https://code.google.com/p/mztab/}}
formats are available via the
\Rfunction{readMgfData}/\Rfunction{writeMgfData} and
\Rfunction{readMzTabData}/\Rfunction{writeMzTabData} functions,
respectively. An example for the latter is shown in the next section.

\section{Quantitative proteomics}

As an running example throughout this document, we will use a TMT
6-plex data set, \texttt{PXD000001} to illustrate quantitative data
processing.  The code chunk below first downloads this data file from
the ProteomeXchange server using the \Biocpkg{rpx} package.

\subsection{The \texttt{mzTab} format}

The first code chunk downloads the \texttt{mzTab} data from the
ProteomeXchange repository \cite{Vizcaino2014}.

<<downloadmztab, tidy = FALSE>>=
## Experiment information
library("rpx")
px1 <- PXDataset("PXD000001")
px1
pxfiles(px1)
## Downloading the mzTab data
mztab <- pxget(px1, "PXD000001_mztab.txt")
mztab
@

The code below loads the \texttt{mzTab} file into \R{} and generates
an \Robject{MSnSet} instance\footnote{Here, we specify \texttt{mzTab}
  format version 0.9. Recent files have been generated according to
  the latest specifications, version 1.0, and the \texttt{version}
  does not need to be specified explicitly.}, removes missing values
and calculates protein intensities by summing the peptide quantitation
data. Figure \ref{fig:matplot} illustrates the intensities for 5
proteins.


<<mztab, tidy = FALSE>>=
## Load mzTab peptide data
qnt <- readMzTabData(mztab, what = "PEP", version = "0.9")
sampleNames(qnt) <- reporterNames(TMT6)
head(exprs(qnt))
## remove missing values
qnt <- filterNA(qnt)
processingData(qnt)

## combine into proteins
## - using the 'accession' feature meta data
## - sum the peptide intensities
protqnt <- combineFeatures(qnt,
                           groupBy = fData(qnt)$accession,
                           fun = sum)
@



\begin{figure}[!ht]
<<matplot, dev='pdf', echo=TRUE, fig.width=5.5, fig.height=5.5, fig.keep='last', out.width='.6\\linewidth', tidy=FALSE>>=
cls <- brewer.pal(5, "Set1")
matplot(t(tail(exprs(protqnt), n = 5)), type = "b",
        lty = 1, col = cls,
        ylab = "Protein intensity (summed peptides)",
        xlab = "TMT reporters")
legend("topright", tail(featureNames(protqnt), n=5),
       lty = 1, bty = "n", cex = .8, col = cls)
@
\caption{Protein quantitation data. }
\label{fig:matplot}
\end{figure}

<<mztab2>>=
qntS <- normalise(qnt, "sum")
qntV <- normalise(qntS, "vsn")
qntV2 <- normalise(qnt, "vsn")

acc <- c("P00489", "P00924",
         "P02769", "P62894",
         "ECA")

idx <- sapply(acc, grep, fData(qnt)$accession)
idx2 <- sapply(idx, head, 3)
small <- qntS[unlist(idx2), ]

idx3 <- sapply(idx, head, 10)
medium <- qntV[unlist(idx3), ]

m <- exprs(medium)
colnames(m) <- c("126", "127", "128",
                 "129", "130", "131")
rownames(m) <- fData(medium)$accession
rownames(m)[grep("CYC", rownames(m))] <- "CYT"
rownames(m)[grep("ENO", rownames(m))] <- "ENO"
rownames(m)[grep("ALB", rownames(m))] <- "BSA"
rownames(m)[grep("PYGM", rownames(m))] <- "PHO"
rownames(m)[grep("ECA", rownames(m))] <- "Background"

cls <- c(brewer.pal(length(unique(rownames(m)))-1, "Set1"),
         "grey")
names(cls) <- unique(rownames(m))
wbcol <- colorRampPalette(c("white", "darkblue"))(256)
@ %% $

\begin{figure}[!ht]
<<heatmap, dev='pdf', echo=TRUE, fig.width=5.5, fig.height=5.5, fig.keep='last', out.width='.6\\linewidth'>>=
heatmap(m, col = wbcol, RowSideColors=cls[rownames(m)])
@
\caption{A heatmap. }
\label{fig:heatmap}
\end{figure}


\begin{figure}[!ht]
<<spikes, dev='pdf', echo=TRUE, fig.width=9, fig.height=5, fig.keep='all', out.width='1\\linewidth', tidy=FALSE>>=
dfr <- data.frame(exprs(small),
                  Protein = as.character(fData(small)$accession),
                  Feature = featureNames(small),
                  stringsAsFactors = FALSE)
colnames(dfr) <- c("126", "127", "128", "129", "130", "131",
                   "Protein", "Feature")
dfr$Protein[dfr$Protein == "sp|P00924|ENO1_YEAST"] <- "ENO"
dfr$Protein[dfr$Protein == "sp|P62894|CYC_BOVIN"]  <- "CYT"
dfr$Protein[dfr$Protein == "sp|P02769|ALBU_BOVIN"] <- "BSA"
dfr$Protein[dfr$Protein == "sp|P00489|PYGM_RABIT"] <- "PHO"
dfr$Protein[grep("ECA", dfr$Protein)] <- "Background"
dfr2 <- melt(dfr)
ggplot(aes(x = variable, y = value, colour = Protein),
       data = dfr2) +
  geom_point() +
  geom_line(aes(group=as.factor(Feature)), alpha = 0.5) +
  facet_grid(. ~ Protein) + theme(legend.position="none") +
  labs(x = "Reporters", y = "Normalised intensity")
@ %% $
\caption{Spikes plot using \CRANpkg{ggplot2}.}
\label{fig:spikes}
\end{figure}

\subsection{Third-party data}

It is possible to import any arbitrary text-based spreadsheet as
\Rclass{MSnSet} object using either \Rfunction{readMSnSet} or
\Rfunction{readMSnSet2}. The former takes three spreadsheets as input
(for the expression data and the feature and sample meta-data). The
latter uses a single spreadsheet and a vector of expression columns to
populate the assay data and the feature meta-data. Detailed examples
are provided in the \texttt{MSnbase-io} vignette, that can be
consulted from \R{} with \Rfunction{vignette("MSnbase-io")} or
online\footnote{\url{http://bioconductor.org/packages/release/bioc/vignettes/MSnbase/inst/doc/MSnbase-io.pdf}}.

\clearpage

\subsection{Working with raw data}

We reuse our dedicated \Robject{px1} ProteomeXchange data object to
download the raw data (in \texttt{mzXML} format) and load it with the
\Rfunction{readMSData} from the \Biocpkg{MSnbase} package that
produces a raw data experiment object of class \Robject{MSnExp}. The
raw data is then quantified using the \Rfunction{quantify} method
specifying the TMT 6-plex isobaric tags and a 7$^{th}$ peak of
interest corresponding to the un-dissociated reporter tag peaks (see
the \texttt{MSnbase-demo} vignette in \Biocpkg{MSnbase} for details).

<<mzxmlqnt, cache=TRUE>>=
mzxml <- pxget(px1, "TMT_Erwinia_1uLSike_Top10HCD_isol2_45stepped_60min_01.mzXML")
rawms <- readMSData(mzxml, centroided = TRUE, verbose = FALSE)
qntms <- quantify(rawms, reporters = TMT7, method = "max")
qntms
@

Identification data in the \texttt{mzIdentML} format can be added to
\Robject{MSnExp} or \Robject{MSnSet} instances with the
\Rfunction{addIdentificationData} function. See the function
documentation for examples.

<<qntdf>>=
d <- data.frame(Signal = rowSums(exprs(qntms)[, 1:6]),
                Incomplete = exprs(qntms)[, 7])
d <- log(d)
cls <- rep("#00000050", nrow(qnt))
pch <- rep(1, nrow(qnt))
cls[grep("P02769", fData(qnt)$accession)] <- "gold4" ## BSA
cls[grep("P00924", fData(qnt)$accession)] <- "dodgerblue" ## ENO
cls[grep("P62894", fData(qnt)$accession)] <- "springgreen4" ## CYT
cls[grep("P00489", fData(qnt)$accession)] <- "darkorchid2" ## PHO
pch[grep("P02769", fData(qnt)$accession)] <- 19
pch[grep("P00924", fData(qnt)$accession)] <- 19
pch[grep("P62894", fData(qnt)$accession)] <- 19
pch[grep("P00489", fData(qnt)$accession)] <- 19
@

<<mzp, cache = TRUE, fig.keep='none', warning = FALSE>>=
mzp <- plotMzDelta(rawms, reporters = TMT6, verbose = FALSE) + ggtitle("")
@

\begin{figure}[!ht]
<<plotmzdelta, dev='pdf', echo=TRUE, fig.width=8, fig.height=5, fig.keep='last', out.width='0.9\\linewidth', warning = FALSE>>=
mzp
@
\caption{A m/z delta plot.}
\label{fig:plotmzdelta}
\end{figure}


\begin{figure}[!ht]
<<incompl, dev='pdf', echo=TRUE, fig.width=5.5, fig.height=5.5, fig.keep='last', out.width='.6\\linewidth', tidy=FALSE>>=
plot(Signal ~ Incomplete, data = d,
     xlab = expression(Incomplete~dissociation),
     ylab = expression(Sum~of~reporters~intensities),
     pch = 19,
     col = "#4582B380")
grid()
abline(0, 1, lty = "dotted")
abline(lm(Signal ~ Incomplete, data = d), col = "darkblue")
@
\caption{Incomplete dissociation.}
\label{fig:incompl}
\end{figure}


\begin{figure}[!ht]
<<maplot, dev='pdf', echo=TRUE, fig.width=5.5, fig.height=5.5, fig.keep='last', out.width='.6\\linewidth'>>=
MAplot(qnt[, c(4, 2)], cex = .9, col = cls, pch = pch, show.statistics = FALSE)
@
\caption{MAplot on an \Robject{MSnSet} instance.}
\label{fig:maplot}
\end{figure}

\clearpage

\subsection{The \CRANpkg{MALDIquant} package}

This section illustrates some of \CRANpkg{MALDIquant}'s data
processing capabilities \cite{Gibb2012}.  The code is taken from the
\texttt{processing-peaks.R} script downloaded from the package
homepage\footnote{\url{http://strimmerlab.org/software/maldiquant/}}.

\subsubsection*{Loading the data}

<<mqload, tidy=FALSE>>=
## load packages
library("MALDIquant")
library("MALDIquantForeign")
## getting test data
datapath <-
  file.path(system.file("Examples",
                        package = "readBrukerFlexData"),
            "2010_05_19_Gibb_C8_A1")
dir(datapath)
sA1 <- importBrukerFlex(datapath, verbose=FALSE)
# in the following we use only the first spectrum
s <- sA1[[1]]

summary(mass(s))
summary(intensity(s))
head(as.matrix(s))
@

\begin{figure}[!ht]
<<mqplot, dev='pdf', echo=TRUE, fig.width=7, fig.height=5.5, fig.keep='last', out.width='.6\\linewidth'>>=
plot(s)
@
\caption{Spectrum plotting in \CRANpkg{MALDIquant}.}
\label{fig:mqplot}
\end{figure}

\subsubsection*{Preprocessing}

<<mqpreproc>>=
## sqrt transform (for variance stabilization)
s2 <- transformIntensity(s, method="sqrt")
s2

## smoothing - 5 point moving average
s3 <- smoothIntensity(s2, method="MovingAverage", halfWindowSize=2)
s3

## baseline subtraction
s4 <- removeBaseline(s3, method="SNIP")
s4
@

\subsubsection*{Peak picking}

<<mqred>>=
## peak picking
p <- detectPeaks(s4)
length(p) # 181
peak.data <- as.matrix(p) # extract peak information
@


\begin{figure}[!ht]
<<mqplot2, dev='pdf', echo=TRUE, fig.width=10, fig.height=5, fig.keep='high', out.width='1\\linewidth'>>=
par(mfrow=c(2,3))
xl <- range(mass(s))
# use same xlim on all plots for better comparison
plot(s, sub="", main="1: raw", xlim=xl)
plot(s2, sub="", main="2: variance stabilisation", xlim=xl)
plot(s3, sub="", main="3: smoothing", xlim=xl)
plot(s4, sub="", main="4: base line correction", xlim=xl)
plot(s4, sub="", main="5: peak detection", xlim=xl)
points(p)
top20 <- intensity(p) %in% sort(intensity(p), decreasing=TRUE)[1:20]
labelPeaks(p, index=top20, underline=TRUE)
plot(p, sub="", main="6: peak plot", xlim=xl)
labelPeaks(p, index=top20, underline=TRUE)
@
\caption{Spectrum plotting in \CRANpkg{MALDIquant}.}
\label{fig:mqplot}
\end{figure}

\clearpage

\subsection{Working with peptide sequences}

<<isotopes, tidy = FALSE, warning = FALSE>>=
library(IPPD)
library(BRAIN)
atoms <- getAtomsFromSeq("SIVPSGASTGVHEALEMR")
unlist(atoms)

library(Rdisop)
pepmol <- getMolecule(paste0(names(atoms),
                             unlist(atoms),
                             collapse = ""))
pepmol

##
library(OrgMassSpecR)
data(itraqdata)

simplottest <-
  itraqdata[featureNames(itraqdata) %in% paste0("X", 46:47)]
sim <- SpectrumSimilarity(as(simplottest[[1]], "data.frame"),
                          as(simplottest[[2]], "data.frame"),
                          top.lab = "itraqdata[['X46']]",
                          bottom.lab = "itraqdata[['X47']]",
                          b = 25)
title(main = paste("Spectrum similarity", round(sim, 3)))

MonoisotopicMass(formula = list(C = 2, O = 1, H=6))
molecule <- getMolecule("C2H5OH")
molecule$exactmass
## x11()
## plot(t(.pepmol$isotopes[[1]]), type = "h")

## x <- IsotopicDistribution(formula = list(C = 2, O = 1, H=6))
## t(molecule$isotopes[[1]])
## par(mfrow = c(2,1))
## plot(t(molecule$isotopes[[1]]), type = "h")
## plot(x[, c(1,3)], type = "h")

## data(myo500)
## masses <- c(147.053, 148.056)
## intensities <- c(93, 5.8)
## molecules <- decomposeIsotopes(masses, intensities)

## experimental eno peptides
exppep <-
  as.character(fData(qnt[grep("ENO", fData(qnt)[, 2]), ])[, 1]) ## 13
minlength <- min(nchar(exppep))


if (!file.exists("P00924.fasta"))
    eno <- download.file("http://www.uniprot.org/uniprot/P00924.fasta",
                         destfile = "P00924.fasta")
eno <- paste(readLines("P00924.fasta")[-1], collapse = "")
enopep <- Digest(eno, missed = 1)
nrow(enopep) ## 103
sum(nchar(enopep$peptide) >= minlength) ## 68
pepcnt <- enopep[enopep[, 1] %in% exppep, ]
nrow(pepcnt) ## 13
@

The following code chunks demonstrate how to use the \Biocpkg{cleaver} package
for in-silico cleavage of polypeptides, e.g. cleaving of
\emph{Gastric juice peptide 1 (P01358)} using \emph{Trypsin}:
<<cleaver, tidy = FALSE>>=
library(cleaver)
cleave("LAAGKVEDSD", enzym = "trypsin")
@

Sometimes cleavage is not perfect and the enzym miss some cleavage positions:

<<cleaver_missing, tidy = FALSE>>=
## miss one cleavage position
cleave("LAAGKVEDSD", enzym = "trypsin", missedCleavages = 1)

## miss zero or one cleavage positions
cleave("LAAGKVEDSD", enzym = "trypsin", missedCleavages = 0:1)
@


Example code to generate an Texshade image to be included directly in
a Latex document or \R{} vignette is presented below.  The \R{} code
generates a Texshade environment and the annotated sequence display
code that is written to a \TeX~file that can itself be included into a
\LaTeX~of Sweave document.

{\scriptsize
\begin{verbatim}
seq1file <- "seq1.tex"
cat("\\begin{texshade}{Figures/P00924.fasta}
     \\setsize{numbering}{footnotesize}
     \\setsize{residues}{footnotesize}
     \\residuesperline*{70}
     \\shadingmode{functional}
     \\hideconsensus
     \\vsepspace{1mm}
     \\hidenames
     \\noblockskip\n", file = seq1file)
tmp <- sapply(1:nrow(pepcnt), function(i) {
  col <- ifelse((i %% 2) == 0, "Blue", "RoyalBlue")
  cat("\\shaderegion{1}{", pepcnt$start[i], "..", pepcnt$stop[i], "}{White}{", col, "}\n",
      file = seq1file, append = TRUE)
})
cat("\\end{texshade}
    \\caption{Visualising observed peptides for the Yeast enolase protein. Peptides are shaded in blue and black.
              The last peptide is a mis-cleavage and overlaps with \\texttt{IEEELGDNAVFAGENFHHGDK}.}
    \\label{fig:seq}
  \\end{center}
\\end{figure}\n\n",
    file = seq1file, append = TRUE)
\end{verbatim}
}


\subsubsection*{$^{15}N$ incorporation}

\begin{figure}[!ht]
<<n15, dev='pdf', echo=TRUE, fig.width=8, fig.height=7, fig.keep='high', out.width='.9\\linewidth', tidy=FALSE, cache=TRUE>>=
## 15N incorporation rates from 0, 0.1, ..., 0.9, 0.95, 1
incrate <- c(seq(0, 0.9, 0.1), 0.95, 1)
inc <- lapply(incrate, function(inc)
              IsotopicDistributionN("YEVQGEVFTKPQLWP", inc))
par(mfrow = c(4,3))
for (i in 1:length(inc))
  plot(inc[[i]][, c(1, 3)], xlim = c(1823, 1848), type = "h",
       main = paste0("15N incorporation at ", incrate[i]*100, "%"))
@
\caption{Isotopic envelope for the \texttt{YEVQGEVFTKPQLWP} peptide at different $^{15}N$ incorporation rates. }
\label{fig:n15}
\end{figure}

\clearpage

\subsection{The \Biocpkg{isobar} package}

The \Biocpkg{isobar} package \cite{Breitwieser2011} provides methods for the statistical
analysis of isobarically tagged MS$^2$ experiments.

%% <<isobarfix, echo=TRUE>>=
%% ## temporary local fix
%% subsetIBSpectra <-
%%   function (x, protein = NULL,
%%             peptide = NULL, direction = "exclude",
%%             specificity =
%%             c(REPORTERSPECIFIC, GROUPSPECIFIC, UNSPECIFIC),
%%             ...)
%% {
%%     if (is.null(protein))
%%         sel.spectra <- spectrumSel(x, peptide = peptide, ...)
%%     else sel.spectra <- spectrumSel(x,
%%                                     protein = protein,
%%                                     specificity = specificity,
%%         ...)
%%     if (direction == "exclude")
%%         sel.spectra <- !sel.spectra
%%     for (aden in assayDataElementNames(x)) {
%%         assayDataElement(x, aden) <-
%%           assayDataElement(x, aden)[sel.spectra,             ]
%%     }
%%     ## changed this from as.data.frame
%%     pg.df <- as(proteinGroup(x), "data.frame")
%%     proteinGroup(x) <-
%%       ProteinGroup(pg.df[pg.df[, "spectrum"] %in%
%%         fData(x)[sel.spectra, "spectrum"], ])
%%     featureData(x) <- as(fData(x)[sel.spectra, ],
%%                          "AnnotatedDataFrame")
%%     x
%% }
%% @

<<isobar, cache=TRUE, tidy=FALSE>>=
library(isobar)

## Prepare the PXD000001 data for isobar analysis
.ions <- exprs(qnt)
.mass <- matrix(mz(TMT6), nrow(qnt), byrow=TRUE, ncol = 6)
colnames(.ions) <- colnames(.mass) <-
  reporterTagNames(new("TMT6plexSpectra"))
rownames(.ions) <- rownames(.mass) <-
  paste(fData(qnt)$accession, fData(qnt)$sequence, sep = ".")
pgtbl <- data.frame(spectrum = rownames(.ions),
                    peptide = fData(qnt)$sequence,
                    modif = ":",
                    start.pos = 1,
                    protein = fData(qnt)$accession,
                    accession = fData(qnt)$accession)
x <- new("TMT6plexSpectra", pgtbl, .ions, .mass)
featureData(x)$proteins <- as.character(fData(qnt)$accession)

x <- correctIsotopeImpurities(x) ## using identity matrix here
x <- normalize(x, per.file = FALSE)
## spikes
spks <- c(protein.g(proteinGroup(x), "P00489"),
          protein.g(proteinGroup(x), "P00924"),
          protein.g(proteinGroup(x), "P02769"),
          protein.g(proteinGroup(x), "P62894"))

cls2 <- rep("#00000040", nrow(x))
pch2 <- rep(1, nrow(x))
cls2[grep("P02769", featureNames(x))] <- "gold4" ## BSA
cls2[grep("P00924", featureNames(x))] <- "dodgerblue" ## ENO
cls2[grep("P62894", featureNames(x))] <- "springgreen4" ## CYT
cls2[grep("P00489", featureNames(x))] <- "darkorchid2" ## PHO
pch2[grep("P02769", featureNames(x))] <- 19
pch2[grep("P00924", featureNames(x))] <- 19
pch2[grep("P62894", featureNames(x))] <- 19
pch2[grep("P00489", featureNames(x))] <- 19

nm <- NoiseModel(x)
ib.background <- subsetIBSpectra(x, protein=spks,
                                 direction = "exclude")
nm.background <- NoiseModel(ib.background)
ib.spks <- subsetIBSpectra(x, protein = spks,
                           direction="include",
                           specificity="reporter-specific")
nm.spks <- NoiseModel(ib.spks, one.to.one=FALSE, pool=TRUE)

ratios <- 10^estimateRatio(x, nm,
                           channel1="127", channel2="129",
                           protein = spks,
                           combine = FALSE)[, "lratio"]

res <- estimateRatio(x, nm,
                     channel1="127", channel2="129",
                     protein = unique(fData(x)$proteins),
                     combine = FALSE,
                     sign.level = 0.01)[, c(1, 2, 6, 8)]
res <- as.data.frame(res)
res$lratio <- -(res$lratio)

cls3 <- rep("#00000050", nrow(res))
pch3 <- rep(1, nrow(res))
cls3[grep("P02769", rownames(res))] <- "gold4" ## BSA
cls3[grep("P00924", rownames(res))] <- "dodgerblue" ## ENO
cls3[grep("P62894", rownames(res))] <- "springgreen4" ## CYT
cls3[grep("P00489", rownames(res))] <- "darkorchid2" ## PHO
pch3[grep("P02769", rownames(res))] <- 19
pch3[grep("P00924", rownames(res))] <- 19
pch3[grep("P62894", rownames(res))] <- 19
pch3[grep("P00489", rownames(res))] <- 19

rat.exp <- c(PHO = 2/2,
             ENO = 5/1,
             BSA = 2.5/10,
             CYT = 1/1)
@ %% $


\begin{figure}[!ht]
<<ibplot, dev='pdf', echo=TRUE, fig.width=5, fig.height=5, fig.keep='last'>>=
maplot(x,
       noise.model = c(nm.background, nm.spks, nm),
       channel1="127", channel2="129",
       pch = 19, col = cls2,
       main = "Spectra MA plot")
abline(h = 1, lty = "dashed", col = "grey")
legend("topright",
       c("BSA", "ENO", "CYT", "PHO"),
       pch = 19, col = c("gold4", "dodgerblue",
                   "springgreen4", "darkorchid2"),
       bty = "n", cex = .7)
@
\caption{Result from the \Biocpkg{isobar} pipeline. }
\label{fig:ibplot}
\end{figure}

\clearpage

\subsection{The \Biocpkg{synapter} package}

The \Biocpkg{synapter} \cite{synapter} package comes with a detailed
vignette that describes how to prepare the MS$^E$ data and then
process it in \R{}. Several interfaces are available provided the user
with maximum control, easy batch processing capabilities or a
graphical user interface. The conversion into \Robject{MSnSet}
instances and filter and combination thereof as well as statistical
analysis are also described.

<<synapter, eval=FALSE>>=
## open the synapter vignette
library("synapter")
synapterGuide()
@

\section{MS$^2$ spectra identification}

At the moment two packages allow the user to run peptide identifications from
within R. Each of the packages interface to an external peptide database search
tool and have more or less the same workflow, though their syntax differs:

\begin{enumerate}
\item Prepare the input data.
\item Run the search.
\item Import the search results and extract the peptides and proteins
\end{enumerate}

\subsection{X! Tandem}
Following Bioconductor 2.12 the \Biocpkg{rTANDEM} package provides the means
to run the popular X! Tandem software \cite{Craig2004}.

Using example code/data from the \Biocpkg{rTANDEM} vignette/package, the
following is an example of a typical workflow

\subsubsection{Preparation of the input data}

<<rtandem1, tidy = FALSE>>=
library(rTANDEM)
taxonomy <- rTTaxo(taxon = "yeast",
                   format = "peptide",
                   URL = system.file(
                     "extdata/fasta/scd.fasta.pro",
                     package="rTANDEM"))
param <- rTParam()
param <- setParamValue(param,
                       'protein', 'taxon',
                       value="yeast")
param <- setParamValue(param, 'list path',
                       'taxonomy information', taxonomy)
param <- setParamValue(param,
                       'list path', 'default parameters',
                       value = system.file(
                         "extdata/default_input.xml",
                         package="rTANDEM"))
param <- setParamValue(param, 'spectrum', 'path',
                       value = system.file(
                         "extdata/test_spectra.mgf",
                         package="rTANDEM"))
param <- setParamValue(param, 'output', 'xsl path',
                       value = system.file(
                         "extdata/tandem-input-style.xsl",
                         package="rTANDEM"))
param <- setParamValue(param, 'output', 'path',
                       value = paste(getwd(),
                         "output.xml", sep="/"))
@


\subsubsection{Performing the search}

The analysis is run using the \Rfunction{tandem} function (see also the
\Rfunction{rtandem} function), which returns the results data file path (only
the file name is displayed below).

<<rtandem2>>=
resultPath <- tandem(param)
basename(resultPath)
@

\subsubsection{Import and analyse results}

<<rtandem3>>=
res <- GetResultsFromXML(resultPath)
## the inferred proteins
proteins <- GetProteins(res,
                        log.expect = -1.3,
                        min.peptides = 2)
proteins[, -(4:5), with = FALSE]
## the identified peptides for YFR053C
peptides <- GetPeptides(protein.uid = 1811,
                        results = res,
                        expect = 0.05)
peptides[, c(1:4, 9, 10:16), with = FALSE]
@

More details are provided in the vignette available with
\Rfunction(vignette("rTANDEM")), for instance the extraction of degenerated
peptides, i.e. peptides found in multiple proteins.


\bigskip

The \Biocpkg{shinyTANDEM} package offers a web-based graphical
interface to \Biocpkg{rTANDEM}.

\subsection{MS-GF+}
With the release of Bioconductor 3.0 the \Biocpkg{MSGFplus} package has
provided an interface to MS-GF+ \cite{Kim:2008go, Kim:2010ks}. The package
vignette describe in detail the different ways an MS-GF+ analysis can be
initiated and only a simple example will be given here:

\subsubsection{Preparation of the input data}

<<msgf1>>=
library("MSGFplus")
## Create a parameter object with a set of parameters
param <- msgfPar(database = system.file('extdata',
                                        'milk-proteins.fasta',
                                        package='MSGFplus'),
                 tolerance = '10 ppm',
                 enzyme = 'Trypsin')

## Add parameters after creation
instrument(param) <- 'QExactive'
tda(param) <- TRUE
ntt(param) <- 2

## Add expected modifications
mods(param)[[1]] <- msgfParModification('Carbamidomethyl',
                                        composition = 'C2H3N1O1',
                                        residues = 'C',
                                        type = 'fix',
                                        position = 'any')

mods(param)[[2]] <- msgfParModification(name = 'Oxidation',
                                        mass = 15.994915,
                                        residues = 'M',
                                        type = 'opt',
                                        position = 'any')

nMod(param) <- 2    # Number of allowed modifications per peptide

## Get a summary of your parameters
show(param)
@

\subsubsection{Performing the search}
Initiating the search is done using the \Rfunction{runMSGF} method. As a minimum
it takes a parameter object and a list of raw data files and performs the search
for each data file in sequence. More specialised operations are also possible
such as running it asynchronously, but interested readers should refer to the
\Biocpkg{MSGFplus} vignette for additional information.

The first time a search is initialised the MS-GF+ code is downloaded, so be sure
to have an active internet connection (only applies to the first time a search
is run).

<<msgfplus2, eval=FALSE>>=
result <- runMSGF(param, 'path/to/a/rawfile.mzML')
@

\subsubsection{Import and analyse results}
By default MSGFplus imports the results automatically using \Biocpkg{mzID}. If
only one file was analysed, the return value is an mzID object; if multiple
files are analysed at once the return value is an mzIDCollection object.

If \texttt{import=FALSE} the results are not imported and can be accessed at a
later time using the \Biocpkg{mzID} package (see section~\ref{subsec:mzID} on
page~\pageref{subsec:mzID}).

\subsubsection{Running MS-GF+ through a GUI}
\Biocpkg{MSGFplus} comes with a sister package, \Rpackage{MSGFgui},
which provide a graphic interface to setting up and running MS-GF+
through \R. Besides facilitating MS-GF+ analyses, which is arguably
just as easy from the command line, it provides an intuitive way to
investigate and evaluate the resulting identification data.


\begin{figure}[!ht]
  \centering
    \includegraphics[width=.6\textwidth]{figures/MSGFgui.png}
    \caption{A screenshot of MSGFgui}
    \label{fig:MSGFgui}
\end{figure}

Figure~\ref{fig:MSGFgui} shows an example of using \Rpackage{MSGFgui}. It is
possible to gradually drill down in the results starting from the protein level
and ending at the raw spectrum level. mzIdentML files already created with
MS-GF+ (using \Biocpkg{MSGFplus} or in other ways) can easily be imported into
the gui to take advantage of the visualisation features, and results can be
exported as either rds (for R), xlsx (for excel) or txt (for everything else)
files.




\subsection{Post-search Filtering of MS/MS IDs Using \Biocpkg{MSnID}}

\emph{The main purpose of \Biocpkg{MSnID} package is to make sure that
  the peptide and protein identifications resulting from MS/MS
  searches are sufficiently confident for a given application.} MS/MS
peptide and protein identification is a process that prone to
uncertanities.  A typical and currently most reliable way to quantify
uncertainty in the list of identify spectra, peptides or proteins
relies on so-called decoy database. For bottom-up (i.e. involving
protein digestion) approaches a common way to construct a decoy
database is simple inversion of protein amino-acid sequences. If the
spectrum matches to normal protein sequence it can be true or false
match. Matches to decoy part of the database are false only (excluding
the palindromes). Therefore the false discovery rate (FDR) of
identifications can be estimated as ratio of hits to decoy over normal
parts of the protein sequence database. There are multiple levels of
identification that FDR can be estimated for. First, is at the level
of peptide/protein- to-spectrum matches. Second is at the level of
unique peptide sequences. Note, true peptides tend to be identified by
more then one spectrum. False peptide tend to be sporadic. Therefore,
after collapsing the redundant peptide identifications from multiple
spectra to the level of unique peptide sequence, the FDR typically
increases. The extend of FDR increase depends on the type and
complexity of the sample. The same trend is true for estimating the
identification FDR at the protein level. True proteins tend to be
identified with multiple peptides, while false protein identifications
are commonly covered only by one peptide. Therefore FDR estimate tend
to be even higher for protein level compare to peptide level.  The
estimation of the FDR is also affected by the number of LC-MS (runs)
datasets in the experiment. Again, true identifications tend to be
more consistent from run to run, while false are sporadic. After
collapsing the redundancy across the runs, the number of true
identification reduces much stronger compare to false
identifications. Therefore, the peptide and protein FDR estimates need
to be re-evaluated.  The main objective of the MSnID package is to
provide convenience tools for handling tasks on estimation of FDR,
defining and optimizing the filtering criteria and ensuring confidence
in MS/MS identification data. The user can specify the criteria for
filtering the data (e.g. goodness or p-value of matching of
experimental and theoretical fragmentation mass spectrum, deviation of
theoretical from experimentally measured mass, presence of missed
cleavages in the peptide sequence, etc), evaluate the performance of
the filter judging by FDRs at spectrum, peptide and protein levels,
and finally optimize the filter to achieve the maximum number of
identifications while not exceeding maximally allowed FDR upper
threshold.

\subsubsection{Starting Project \& Importing Data}

To start a project one have to specify a directory. Currently the only
use of the directory is for storing cached results.

<<MSnIDstart>>=
library("MSnID")
msnid <- MSnID(".")
@

Data can imported as \Rcode{data.frame} or read from mzIdentML file.

<<MSnIDdataImport>>=
PSMresults <- read.delim(system.file("extdata", "human_brain.txt",
                                     package="MSnID"),
                         stringsAsFactors=FALSE)
psms(msnid) <- PSMresults
show(msnid)

mzids <- system.file("extdata", "c_elegans.mzid.gz", package="MSnID")
msnid <- read_mzIDs(msnid, mzids)
show(msnid)
@

\subsubsection{Analysis of Peptide Sequences}

A particular properties of peptide sequences we are interested in are

\begin{enumerate}
\item irregular cleavages at the termini of the peptides and
\item missing cleavage site within the peptide sequences.
\end{enumerate}


A particular properties of peptide sequences we are interested in are
(1) irregular cleavages at the termini of the peptides and (2) missing
cleavage site within the peptide sequences: 

\begin{itemize}
\item Counting the number of irregular cleavage termimi (0, 1 or 2) in
  peptides sequence creates a new column \texttt{numIrregCleavages}.
\item Counting the number of missed cleavages in peptides sequence
  correspondingly creates a \texttt{numMissCleavages} column.
\end{itemize}

The default regular expressions for the \texttt{validCleavagePattern}
and \texttt{missedCleavagePattern} correspond to trypsin specificity.


<<MSnIDsequence>>=
msnid <- assess_termini(msnid, validCleavagePattern="[KR]\\.[^P]")
msnid <- assess_missed_cleavages(msnid, missedCleavagePattern="[KR](?=[^P$])")
prop.table(table(msnid$numIrregCleavages))
@


Now the object has two more columns, \texttt{numIrregCleavages} and
\texttt{numMissCleavages}, evidently corresponding to the number of
termini with irregular cleavages and number of missed cleavages within
the peptide sequence. The figure below shows that peptides with 2 or
more missed cleavages are likely to be false identifications.

<<MSnIDmissedCleavagesPlot, dev='pdf', fig.width=8, fig.height=4, out.width='.7\\textwidth'>>=
pepCleav <- unique(psms(msnid)[,c("numMissCleavages", "isDecoy", "peptide")])
pepCleav <- as.data.frame(table(pepCleav[,c("numMissCleavages", "isDecoy")]))
library("ggplot2")
ggplot(pepCleav, aes(x=numMissCleavages, y=Freq, fill=isDecoy)) +
    geom_bar(stat='identity', position='dodge') +
    ggtitle("Number of Missed Cleavages")
@

\subsubsection{Defining the Filter}

The criteria that will be used for filtering the MS/MS data has to be present
in the \Robject{MSnID} object. We will use -log10 transformed MS-GF+
Spectrum E-value, reflecting the goodness of match experimental and
theoretical fragmentation patterns as one the filtering criteria.
Let's store it under the "msmsScore" name. The score density distribution
shows that it is a good discriminant between non-decoy (red)
and decoy hits (green).


For alternative MS/MS search engines refer to the engine-specific manual for
the names of parameters reflecting the quality of MS/MS spectra matching.
Examples of such parameters are \Rcode{E-Value} for X!Tandem
and \Rcode{XCorr} and \Rcode{$\Delta$Cn2} for SEQUEST.


As a second criterion we will be using the absolute mass measurement
error (in ppm units) of the parent ion. The mass measurement errors tend to
be small for non-decoy (enriched with real identificaiton) hits (red line) and
is effectively uniformly distributed for decoy hits.

<<MSnIDfilteringCriteria>>=
msnid$msmsScore <- -log10(msnid$`MS-GF:SpecEValue`)
msnid$absParentMassErrorPPM <- abs(mass_measurement_error(msnid))
@

MS/MS fiters are handled by a special \Rclass{MSnIDFilter} class
objects.  Individual filtering criteria can be set by name (that is
present in \Rcode{names(msnid)}), comparison operator (>, <, = , ...)
defining if we should retain hits with higher or lower given the
threshold and finally the threshold value itself. The filter below set
in such a way that retains only those matches that has less then 5 ppm
of parent ion mass measurement error and more the
$10^7$ MS-GF:SpecEValue.

<<MSnIDsettingFilter>>=
filtObj <- MSnIDFilter(msnid)
filtObj$absParentMassErrorPPM <- list(comparison="<", threshold=5.0)
filtObj$msmsScore <- list(comparison=">", threshold=8.0)
show(filtObj)
@

The stringency of the filter can be evaluated at different levels.

<<MSnIDfilterAssessment>>=
evaluate_filter(msnid, filtObj, level="PSM")
evaluate_filter(msnid, filtObj, level="peptide")
evaluate_filter(msnid, filtObj, level="accession")
@

\subsubsection{Optimizing the Filter}

The threshold values in the example above are not necessarily optimal and set
just be in the range of probable values. Filters can be optimized to ensure
maximum number of identifications (peptide-to-spectrum matches,
unique peptide sequences or proteins) within a given FDR upper limit.

First, the filter can be optimized simply by stepping through
individual parameters and their combinations. The idea has been described in
\cite{Piehowski2013a}. The resulting \Robject{MSnIDFilter} object can be
used for final data filtering or can be used as a good starting parameters for
follow-up refining optimizations with more advanced algorithms.

<<MSnIDfilterOptimization1>>=
filtObj.grid <- optimize_filter(filtObj, msnid, fdr.max=0.01,
                                method="Grid", level="peptide",
                                n.iter=500)
show(filtObj.grid)
@

The resulting \Rcode{filtObj.grid} can be further fine tuned with such
optimization routines as simulated annealing or Nelder-Mead optimization.

<<MSnIDfilterOptimization2>>=
filtObj.nm <- optimize_filter(filtObj.grid, msnid, fdr.max=0.01,
                                method="Nelder-Mead", level="peptide",
                                n.iter=500)
show(filtObj.nm)
@

Evaluate non-optimized and optimized filters.

<<MSnIDfilterAssessment2>>=
evaluate_filter(msnid, filtObj, level="peptide")
evaluate_filter(msnid, filtObj.grid, level="peptide")
evaluate_filter(msnid, filtObj.nm, level="peptide")
@

Finally applying filter to remove predominantly false identifications.

<<MSnIDapplyFilter>>=
msnid <- apply_filter(msnid, filtObj.nm)
show(msnid)
@

Removing hits to decoy and contaminant sequences using the same
\Rcode{apply\_filter} method.

<<MSnIDremovingDecoyAndContaminants>>=
msnid <- apply_filter(msnid, "isDecoy == FALSE")
show(msnid)
msnid <- apply_filter(msnid, "!grepl('Contaminant',accession)")
show(msnid)
@

\subsubsection{Interface with Other Bioconductor Packages}

One can extract the entire PSMs tables as \Rcode{data.frame} or \Rcode{data.table}

<<MSnIDgetDataOut1>>=
psm.df <- psms(msnid)
psm.dt <- as(msnid, "data.table")
@

If only interested in the non-redundant list of confidently identified
peptides or proteins

<<MSnIDgetDataOut2>>=
peps <- peptides(msnid)
head(peps)
prots <- accessions(msnid)
head(prots)
prots <- proteins(msnid) # may be more intuitive then accessions
head(prots)
@

The \Biocpkg{MSnID} package is aimed at providing convenience
functionality to handle MS/MS identifications. Quantification
\textit{per se} is outside of the scope of the package. The only type
of quantitation that can be seamlessly tied with MS/MS identification
analysis is so-called \emph{spectral counting} approach. In such an
approach a peptide abundance is considered to be directly proportional
to the number of matched MS/MS spectra.  In its turn protein abunance
is proportional to the sum of the number of spectra of the matching
peptides. The \Rclass{MSnID} object can be converted to an
\Rclass{MSnSet} object defined in \Biocpkg{MSnbase} that extends
generic Bioconductor \Rclass{eSet} class to quantitative proteomics
data.  The spectral count data can be analyzed with \Biocpkg{msmsEDA},
\Biocpkg{msmsTests} or \Biocpkg{DESeq} packages.

<<MSnIDconvertingToMSnSet>>=
msnset <- as(msnid, "MSnSet")
library("MSnbase")
head(fData(msnset))
head(exprs(msnset))
@

Note, the convertion from \Robject{MSnID} to \Robject{MSnSet} uses
peptides as features. The number of redundant peptide observations
represent so-called spectral count that can be used for rough
quantitative analysis. Summing of all of the peptide counts to a
proteins level can be done with \Rcode{combineFeatures} function from
\Biocpkg{MSnbase} package.

<<MSnIDsummingPeptidesToProteins>>=
msnset <- combineFeatures(msnset,
                            fData(msnset)$accession,
                            redundancy.handler="unique",
                            fun="sum",
                            cv=FALSE)
head(fData(msnset))
head(exprs(msnset))
@

% clean-up
<<eval=TRUE, echo=FALSE, results='hide'>>=
unlink(".Rcache", recursive=TRUE)
@


\section{A comprehensive example}\label{sec:bigex}

This subsection demonstrates a real-world example of using \R{} for
proteomics data processing, starting from download of raw data and
FASTA files with the \Biocpkg{rpx} package, peptide and protein
identification with X!Tandem and \Biocpkg{rTANDEM}, filtering MS/MS
data with \Biocpkg{MSnID} and statistical analysis of spectral counts
with \Biocpkg{msmsTests}.

\subsection{Getting the data}

<<idex1>>=
library("rpx")
id <- "PXD002161"
px <- PXDataset(id)
try(setInternet2(FALSE),silent=TRUE)
library("jsonlite")
addr <- "http://www.ebi.ac.uk:80/pride/ws/archive/%s/list/project/%s"
files <- fromJSON(sprintf(addr, "file", id))$list
assays <- fromJSON(sprintf(addr, "assay", id))$list

files <- subset(files, fileType == 'PEAK',
                select=c("assayAccession","fileName"))
assays <- assays[,c("assayAccession",
                    "experimentalFactor",
                    "proteinCount",
                    "peptideCount",
                    "uniquePeptideCount",
                    "identifiedSpectrumCount",
                    "totalSpectrumCount")]

pttrn <- "Age: young, Diet; fully fed"
assays <- subset(assays, grepl(pttrn, experimentalFactor, fixed=T))
# encode phenotype and sample names
group <- sub(".*Name: Y-(.+?)-FF\\.(\\d)", "\\1", assays$experimentalFactor)
splnm <- sub(".*Name: Y-(.+?)-FF\\.(\\d)", "\\1_\\2", assays$experimentalFactor)

assays <- with(assays, {data.frame(assayAccession,
                                   phenotype=sub(".*Name: Y-(.+?)-FF\\.(\\d)",
                                                 "\\1", experimentalFactor),
                                   sampleName=sub(".*Name: Y-(.+?)-FF\\.(\\d)", 
                                                  "\\1_\\2", experimentalFactor),
                                   stringsAsFactors=F)})
files <- subset(files, assayAccession %in% assays$assayAccession)

## pxget(px, files$fileName) # fetch them from PX

files$datasetName <- sub('.mzML.gz','', files$fileName, fixed=TRUE)
meta <- merge(files[,c("assayAccession","datasetName")], assays)
rownames(meta) <- meta$datasetName
meta <- meta[order(meta$sampleName),]
rownames(meta) <- NULL

## library("R.utils")
## sapply(list.files(pattern = "mzML.gz"), gunzip)
@

Now we have \texttt{*.mzML} files for MS/MS search. Let's download
FASTA file from the current release of the Wormbase. We will leverage
Bioconductor's `Biostrings` library to reverse the protein sequence
and append them to the original FASTA file. The reverse sequences will
be use for estimate of the false discovery rate of peptide-to-spectrum
matches, peptide and protein identifications.



<<idex2>>=
library("Biostrings")
fasta_location <-  "ftp://ftp.wormbase.org/pub/wormbase/releases/WS250/species/c_elegans/PRJNA13758/c_elegans.PRJNA13758.WS250.protein.fa.gz"
fwd.seqs <- readAAStringSet(fasta_location, format="fasta",
                            nrec=-1L, skip=0L, use.names=TRUE)
rev.seqs <- reverse(fwd.seqs)
names(rev.seqs) <- paste("XXX", names(rev.seqs), sep='_')
fwd.rev.seqs <- append( fwd.seqs, rev.seqs)
writeXStringSet(x=fwd.rev.seqs, filepath="c_elegans_fwd_rev.fasta", format="fasta")
@

\subsection{Peptide identification}

Setting up X!Tandem parameter files.

<<idex3>>=
library("rTANDEM")
param <- setParamOrbitrap()
taxonomy <- rTTaxo(taxon="celegans",
                   format="peptide",
                   URL= "c_elegans_fwd_rev.fasta")
param <- setParamValue(param, 'list path', 'taxonomy information', taxonomy)
param <- setParamValue(param, 'protein', 'taxon', value='celegans')

def.input.path <- system.file("extdata/default_input.xml", package="rTANDEM")
param <- setParamValue(param, 'list path', 'default parameters',
                       value=def.input.path)

param <- setParamValue(param, "output", "message", "r-for-proteomics ")
param <- setParamValue(param, "refine", value="no")
@

Note, we will be executing X!Tandem on all available cores on the
computer. To determine the number of cores we leverage
\Rfunction{detectCores()} function from the \CRANpkg{parallel}
package.

<<expar>>=
library("parallel")
param <- setParamValue(param, "spectrum", "threads", detectCores())
@

Actuall excetion of the X!Tandem searches. As the output we will
capture the names of corresponging XML files with the MS/MS search
results.


<<rtout>>=
output.files <- lapply(sub("\\.gz","",files$fileName),
                       function(x){
                           param <- setParamValue(param, 'spectrum', 'path', value=x)
                           output.file <- tandem(param)})
@

Since X!Tandem reports the results in its own XML format, parsing then
is a little bit involved process. As we mentioned above, fortunately,
the most recent version of
X!Tandem\footnote{http://www.thegpm.org/tandem/} PILEDRIVER
(2015.04.01) is capable of producing results in \texttt{mzIdentML}
format. Then extracting the results will be trivial with the help of
\Biocpkg{mzID} package. The change will be probably caught up in the
upcoming versions of the \Biocpkg{rTANDEM} package. However, at this
point we will use a custom function that produces a
\Robject{data.frame} with all the necessary columns. The columns that
are required for the \Biocpkg{MSnIDP} package to create an MS/MS
identification object are: accession, calculatedMassToCharge,
chargeState, experimentalMassToCharge, isDecoy, peptide,
spectrumFile and spectrumID.


<<xttodf>>=
library("dplyr")
.P <- MSnID:::.PROTON_MASS # 1.007276

# parse to comply with MSnID
xtandem_to_df <- function(output.file){
    res <- GetResultsFromXML(output.file)
    proteins <- GetProteins(res)
    peptides <- GetPeptides(protein.uid = proteins$uid, results = res)
    peptides <- select(as.data.frame(res@peptides), 
                       prot.uid, spectrum.mh, mh, expect.value, 
                       tandem.score, start.position, end.position,
                       spectrumID = spectrum.id,
                       chargeState = spectrum.z,
                       pepSeq = sequence)
    peptides <- mutate(peptides, 
            calculatedMassToCharge = (mh + .P*(chargeState - 1))/chargeState,
            experimentalMassToCharge = (spectrum.mh + .P*(chargeState - 1))/chargeState,
            spectrum.mh = NULL,
            mh = NULL)
    proteins <- select(as.data.frame(res@proteins),
                       prot.uid=uid, sequence, description)
    proteins <- mutate(proteins, 
                       accession = sub("(\\S+)\t.*", "\\1", description),
                       isDecoy = grepl("XXX_", accession))
    x <- inner_join(peptides, proteins)
    pre <- with(x, substr(sequence, start.position-1, start.position-1))
    pre <- ifelse(pre == "", "-", pre)
    post <- with(x, substr(sequence, end.position+1, end.position+1))
    post <- ifelse(post == "", "-", post)
    x <- mutate(x, 
                peptide = paste(pre,x$pepSeq, post, sep='.'),
                sequence = NULL)
    return(x)
}

out <- lapply(output.files, xtandem_to_df)
for(i in seq_along(out))
    out[[i]]$spectrumFile <- sub("\\.mzML\\.gz","",files$fileName)[i]
out <- Reduce(rbind, out)
@

\subsection{Filtering identification data}

The \Rclass{MSnID} class object from the library of the same name
allows flexible manipulation and filterting of MS/MS identification
results data.

<<msnidm>>=
library(MSnID)
m <- MSnID()
psms(m) <- out
validObject(m)
show(m)
@

Let's take a look and mass measurement error and a large scale. Some
peptide-to-spectrum matches have the error as large as +1 and +2
Dalton. This is due to the fact that the instrument sometime picks
non-monoisotopic peaks for fragmentation. This is more common for the
peptides with large mass.


<<msnisfig, fig.cap="Isotope selection error before and after correction with the \\Rfunction{correct_peak_selection()} function">>=
library(ggplot2)
dM <- with(psms(m),
           round((experimentalMassToCharge-calculatedMassToCharge)*chargeState))
x <- as.data.frame(table(data.frame(dM, isDecoy=m$isDecoy)))
x <- as.data.frame(table(dM, isDecoy=m$isDecoy))
ggplot(x, aes(x=dM, fill=isDecoy, y=Freq)) +
    geom_bar(stat="identity", width=0.25)
@

For correction of the parent ion mass at the isotope-scale level there
is a method with the corresponding name
\Rfunction{correct_peak_selection}.


<<correctpeaksel>>=
m <- correct_peak_selection(m)
dM <- with(psms(m),
           round((experimentalMassToCharge-calculatedMassToCharge)*chargeState))
x <- as.data.frame(table(data.frame(dM, isDecoy=m$isDecoy)))
x <- as.data.frame(table(dM, isDecoy=m$isDecoy))
ggplot(x, aes(x=dM, fill=isDecoy, y=Freq)) +
    geom_bar(stat="identity", width=0.25)
@


The mass measurement error at a finer grain, typicaly related to the
mis-calibrated instument, can be accessed with
\Rfunction{mass_measurement_error} method.

<<parentionmass, fig.caption="Parent ion mass measurement error histograms for non-decoy and decoy peptide-to-spectrum matches">>=
mme <- data.frame(ppm=mass_measurement_error(m), isDecoy=m$isDecoy)
ggplot(mme, aes(x=ppm, fill=isDecoy)) +
    geom_histogram(binwidth=1) +
    xlim(-20,+20) +
    facet_wrap( ~ isDecoy) + 
    scale_y_sqrt()
@


Finding the right set of filtering criteria for MS/MS data is not a
trivial task. For the purpose of flexible filter optimization the
\Biocpkg{MSnID} package has the \Rclass{MSnIDFilter} class. We will
start with defining the criteria we want to filter on.


<<msnidfilt>>=
m$score <- -log10(m$expect.value) # higher the better
m$mme <- abs(mass_measurement_error(m)) # lower the better
fltr <- MSnIDFilter(m)
@

Let define some starting values. What is important is to define what
should be retained higher or lower the given threshold.  Threshold
itself can be set to arbitrary value if "Grid" optimization method
will be used as a first pass. "Grid" optimization loops through a
preset number (`n.iter` argument) of combinations of thresholds
ignoring the initial values. In the filtering criteria optimization
routines, the objective function is the number of peptide-to-spectrum
matches, peptide or protein identifications defined by the `level`
argument. However, if the FDR (estimated using reverse sequences)
exceeds the pre-defined maxium value, the objective function sets to
zero.

<<>>=
fltr$score <- list(comparison=">", threshold=0)
fltr$mme <- list(comparison="<", threshold=0)
fltr.grid <- optimize_filter(fltr, m, fdr.max=0.01,
                             method="Grid", level="peptide",
                             n.iter=1000)
show(fltr.grid)
@

<<>>=
as.numeric(fltr.grid)
evaluate_filter(m, fltr.grid)
@


Further fine-tuning of the filtering criteria can be approached with
Nelder-Mead or simulated annealing optimization techniques specified
by the \texttt{method} arugment.


<<filtsann>>=
fltr.sann <- optimize_filter(fltr.grid, m, fdr.max=0.01,
                             method="SANN", level="peptide",
                             n.iter=1000)
show(fltr.sann)
as.numeric(fltr.sann)
evaluate_filter(m, fltr.sann)
@


Applying the filter.

<<applsann>>=
m <- apply_filter(m, fltr.sann)
@


Visualizing the number of peptides covering the proteins.

<<fig.cap="Number of identified per protein. Almost half of the proteins are 'single-hit wonders', that is identified with one peptide only.">>=
pp <- unique(psms(m)[,c("peptide","accession")])
pep_per_prot <- as.data.frame(table(table(pp$accession)))
pep_per_prot$peptides <- with(pep_per_prot, 
                          ifelse(as.numeric(Var1) > 5, "6+", as.numeric(Var1)))
ggplot(pep_per_prot, 
       aes(x=factor(1), fill=peptides, y=Freq)) + 
    geom_bar(width=1, stat = "identity", position = "stack") + 
    coord_polar(theta = "y") + 
    ylab('') + xlab('') + 
    scale_fill_discrete(name="number of\npeptides per\nprotein")
@


Filtering out single-hit-wonders (that is proteins covered with only
one peptide). Note the massive drop in FDR (down to 0\%). Therefore, if
this particular path of filtering MS/MS identifications seems
stringent the steps can be easily flipped around in the script or
re-arranged in any other way that produce the results suitable for a
particular application.

<<applflitbigex>>=
nms <- names(which(table(pp$accession) > 1))
m <- apply_filter(m, "accession %in% nms")
show(m)
@

\subsection{Exploratory data analysis}

We continue using the \Robject{MSnID} object results from X!Tandem
searches of 10 \textit{C. elegans} files. First, we will convert it to
an \Robject{MSnSet} object that is more taylored to quantitative
analysis and explore the data using the \Biocpkg{msmsEDA} package.

<<>>=
mset <- as(m, "MSnSet")
show(mset)
@


Summing up peptide counts to protein (or assession in general terms)
level. The redundancy of peptide to protein mapping is controlled by
the \texttt{redundancy.handler} argument. In this case we will use
only uniquely mapping peptides for protein quantification.

<<>>=
library("MSnbase")
mset <- combineFeatures(mset,
                        fData(mset)$accession,
                        redundancy.handler="unique",
                        fun="sum",
                        cv=FALSE)
show(mset)
@

Subsetting to the ones that were detected in at least half of the samples

<<>>=
mset <- mset[rowSums(exprs(mset) > 0) >= 6,] # 384 proteins left
@

Updating \texttt{phenoData} using the meta-information on experimental
designed fetched from ProteomeXchange project
page\footnote{\url{http://www.ebi.ac.uk/pride/archive/projects/PXD002161}}.

<<>>=
pData(mset) <- meta[match(sampleNames(mset), meta$datasetName),]
mset$phenotype <- as.factor(mset$phenotype)
sampleNames(mset) <- mset$sampleName
pData(mset)
@

The PCA plot below shows clear separation of control and
\textit{daf-2} mutant \textit{C. elegans} strains.

<<fig.cap="Clear separation of control and daf-2 strains on PCA plot indicates on substantial difference in proteome composition">>=
library("msmsEDA")
counts.pca(mset,
           facs = pData(mset)[,'phenotype',drop=FALSE],
           snms = sampleNames(mset))
@

\subsection{Statistical analysis}

Null hypothesis significance testing using quasi-likelihood Poisson
approach from the \Biocpkg{msmsTests} package. The p-value histogram
shows a substantial increase of p-value frequency in low-value bins
(tailing-up), indicating a significant proteome difference between the
strains.

<<>>=
library(msmsTests)
alt.f <- "y ~ phenotype"
null.f <- "y ~ 1"
div <- colSums(exprs(mset)) # normalization factor
res <- msms.glm.qlll(mset, "y ~ phenotype", "y ~ 1", div=div)
hist(res$p.value, 100)
@



A volcano plot is an alternative way to visualize the estimate fold
and significance of change of change.

<<>>=
lst <- test.results(res, mset, pData(mset)$phenotype,
                    "ctrl","daf2", div, alpha=0.05,
                    minSpC=0, minLFC=1, method="BH")
res.volcanoplot(lst$tres, min.LFC=1, max.pval=0.05, ylbls=NULL, maxy=4)
@

Finally, we use a heatmap to visualize relative protein abundances
across the study samples. In this example we will subset the proteins
only to the ones that have a fold change (up or down) more then 2-fold
and pass the 0.05 threshold for the adjusted p-value.

<<>>=
library("Heatplus")
regulated <- subset(lst$tres, adjp < 0.05 & abs(LogFC) > 1)
# order MSnSet object the daf-16 status
mset <- mset[,order(pData(mset)$phenotype)]
# matrix with regulated proteins
selected.data <- exprs(mset[rownames(regulated),])
# scaling counts from 0 to 1
selected.data <- sweep(selected.data, 1, apply(selected.data, 1, min), '-')
selected.data <- sweep(selected.data, 1, apply(selected.data, 1, max), '/')
heatmap_plus(selected.data,
             scale='none',
             col=colorRampPalette(c("snow","steelblue"))(10))
@

\section{Quality control}\label{sec:qc}

Quality control (QC) is an essential part of any high throughput data
driven approach. Bioconductor has a rich history of QC for various
genomics data and currently two packages support proteomics QC.

\Biocpkg{proteoQC} provides a dedicated a dedicated pipeline that will
produce a dynamic and extensive html report. It uses the
\Biocpkg{rTANDEM} package to automate the generation of identification
data and uses information about the experimental/replication design.


The \Biocpkg{qcmetrics} package is a general framework to define QC
metrics and bundle them together to generate html or pdf reports. It
provides some ready made metrics for MS data and $^{15}$N labelled
data.

\section{Annotation}\label{sec:annot}

In this section, we briefly present some \Bioconductor{} annotation
infrastructure.

We start with the \Biocpkg{hpar} package, an interface to the
\textit{Human Protein Atlas} \cite{Uhlen2005, Uhlen2010}, to retrieve
subcellular localisation information for the \texttt{ENSG00000002746}
ensemble gene.

<<annot1, cache=FALSE>>=
id <- "ENSG00000002746"
library("hpar")
getHpa(id, "SubcellularLoc")
@

Below, we make use of the human annotation package
\Biocannopkg{org.Hs.eg.db} and the Gene Ontology annotation package
\Biocannopkg{GO.db} to retrieve the same information as above.

<<annot2, cache=FALSE, warning = FALSE>>=
library(org.Hs.eg.db)
library(GO.db)
ans <- select(org.Hs.eg.db,
              keys = id, columns = c("ENSEMBL", "GO", "ONTOLOGY"),
              keytype = "ENSEMBL")
ans <- ans[ans$ONTOLOGY == "CC", ]
ans
sapply(as.list(GOTERM[ans$GO]), slot, "Term")
@

Finally, this information can also be retrieved from on-line databases
using the \Biocpkg{biomaRt} package \cite{Durinck2005}.

<<annot3, cache=TRUE>>=
library("biomaRt")
ensembl <- useMart("ensembl",dataset="hsapiens_gene_ensembl")
efilter <- "ensembl_gene_id"
eattr <- c("go_id", "name_1006", "namespace_1003")
bmres <- getBM(attributes=eattr, filters = efilter, values = id, mart = ensembl)
bmres[bmres$namespace_1003 == "cellular_component", "name_1006"]
@ %% $

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Section
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\section{Other packages}\label{sec:packages}

\subsection{\Bioconductor{} packages}


<<protpacks, echo=FALSE, warning=FALSE, cache=TRUE>>=
# biocVersion has to be of type character
biocv <- as.character(biocVersion())

pkTab <- list(Proteomics = proteomicsPackages(biocv),
              MassSpectrometry = massSpectrometryPackages(biocv),
              MassSpectrometryData = massSpectrometryDataPackages(biocv))
@

This section provides a complete list of packages available in the
relevant \Bioconductor{} version \Sexpr{biocv} (as of \today)
\textit{biocView}\footnote{\url{http://www.bioconductor.org/packages/devel/BiocViews.html}}
categories.  Tables \ref{tab:prot}, \ref{tab:ms} and \ref{tab:msdata}
represent the packages for the \texttt{Proteomics}
(\Sexpr{nrow(pkTab[["Proteomics"]])} packages),
\texttt{MassSpectrometry} (\Sexpr{nrow(pkTab[["MassSpectrometry"]])}
packages) and \texttt{MassSpectrometryData}
(\Sexpr{nrow(pkTab[["MassSpectrometryData"]])} experiment packages)
categories.

<<xtabpkg, echo=FALSE, message=FALSE>>=
library("xtable")
@

<<protstab, echo=FALSE, results='asis'>>=
t1 <- xtable(pkTab[["Proteomics"]],
             caption = "Packages available under the \\texttt{Proteomics} \\textit{biocViews} category.",
             table.placement = "thb",
             label = "tab:prot")
align(t1) <- c("l", "l", "p{10cm}", "l")
print(t1,
      include.rownames = FALSE,
      floating = FALSE,
      tabular.environment = 'longtable',
      size = "scriptsize")
@

<<mstab, echo=FALSE, results='asis'>>=
t2 <- xtable(pkTab[["MassSpectrometry"]],
             caption = "Packages available under the \\texttt{MassSpectrometry} \\textit{biocViews} category.",
             table.placement = "thb",
             label = "tab:ms")
align(t2) <- c("l", "l", "p{10cm}", "l")
print(t2,
      include.rownames = FALSE,
      floating = FALSE,
      tabular.environment = 'longtable',
      size = "scriptsize")

@

<<msdatatab, echo=FALSE, results='asis'>>=
t3 <- xtable(pkTab[["MassSpectrometryData"]],
             caption = "Experimental Packages available under the \\texttt{MassSpectrometryData} \\textit{biocViews} category.",
             table.placement = "thb",
             label = "tab:msdata")
align(t3) <- c("l", "l", "p{10cm}", "l")
print(t3,
      include.rownames = FALSE,
      floating = FALSE,
      tabular.environment = 'longtable',
      size = "scriptsize")
@

The tables can easily be generated with the
\Rfunction{proteomicsPackages}, \Rfunction{massSpectrometryPackages}
and \Rfunction{massSpectrometryDataPackages} functions. The respective
package tables can then be interactively explored using the
\Rfunction{display} function.

<<pkgs, eval=FALSE>>=
pp <- proteomicsPackages()
display(pp)
@

\subsection{Other CRAN packages}

<<cntCRAN, echo=FALSE>>=
X <- readLines("http://cran.r-project.org/web/views/ChemPhys.html")
x2 <- grep("Related links:", X)
x1 <- grep("CRAN packages:", X)
np <- length(grep("../packages/", X[x1:x2]))
@

The CRAN task view on Chemometrics and Computational
Physics\footnote{\url{http://cran.r-project.org/web/views/ChemPhys.html}}
is another useful ressource listing \Sexpr{np} packages, including a
set of packages for mass spectrometry and proteomics, some of which
are illustrated in this document.

\begin{description}
\item[\CRANpkg{MALDIquant}] provides tools for quantitative analysis of
  MALDI-TOF mass spectrometry data, with support for baseline
  correction, peak detection and plotting of
  mass spectra \\
  (\url{http://cran.r-project.org/web/packages/MALDIquant/index.html}).
\item[\CRANpkg{OrgMassSpecR}] is for organic/biological mass spectrometry, with
  a focus on graphical display, quantification using stable isotope
  dilution, and protein hydrogen/deuterium exchange
  experiments \\
  (\url{http://cran.r-project.org/web/packages/OrgMassSpecR/index.html}).
\item[\CRANpkg{FTICRMS}] provides functions for Analyzing Fourier Transform-Ion
  Cyclotron
  Resonance Mass Spectrometry Data \\
  (\url{http://cran.r-project.org/web/packages/FTICRMS/index.html}).
\item[\CRANpkg{titan}] provides a GUI to analyze mass spectrometric data on the
  relative abundance
  of two substances from a titration series \\
  (\url{http://cran.r-project.org/web/packages/titan/index.html}).
\item[\CRANpkg{digeR}] provides a GUI interface for analysing 2D DIGE data. It
  allows to perform correlation analysis, score plot, classification,
  feature selection and power analysis for
  2D DIGE experiment data. \\
  (\url{http://cran.r-project.org/web/packages/digeR/index.html})
\item[\CRANpkg{protViz}] helps with quality checks, visualizations and analysis
  of mass spectrometry data, coming from proteomics experiments. The
  package is developed, tested and used at the Functional Genomics
  Center Zurich. \\
  (\url{http://cran.r-project.org/web/packages/protViz/index.html})
\end{description}

\bigskip

Suggestions for additional \R{} packages are welcome and will be added
to the vignette.  Please send suggestions and possibly a short
description and/or a example utilisation with code to
\url{lg390@cam.ac.uk}. The only requirement is that the package must
be available on an official package channel (CRAN, \Bioconductor{},
R-forge, Omegahat), i.e. not only available through a personal web
page.

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Section
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Session information}\label{sec:sessionInfo}

All software and respective versions used in this document, as
returned by \Rfunction{sessionInfo()} are detailed below.

<<sessioninfo, results='asis', echo=FALSE, echo=FALSE>>=
toLatex(sessionInfo(), locale = FALSE)
@

\bibliography{RforProteomics}

\end{document}
